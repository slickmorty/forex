{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from tensorflow import keras\n",
    "from keras import Sequential,activations\n",
    "from keras.layers import Dense,LSTM,Reshape,Dropout,InputLayer,Flatten,Input,BatchNormalization\n",
    "from keras.callbacks import TensorBoard , ModelCheckpoint\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 8)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sp500_with_indicators.csv')\n",
    "df.pop('Unnamed: 0')\n",
    "date_time = pd.to_datetime(df.pop('Date'))\n",
    "timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "\n",
    "#Removing unnecessary columns\n",
    "\n",
    "CLOSE = df.pop('Close')\n",
    "OPEN = df.pop('Open') \n",
    "HIGH = df.pop('High') \n",
    "LOW = df.pop('Low') \n",
    "VOLUME = df.pop('Volume') \n",
    "SPREAD = df.pop('Spread')\n",
    "TICKVOL = df.pop('TickVol') \n",
    "BUY_OR_SELL = df.pop('Class')\n",
    "BUY_OR_SELL_NUMBER = df.pop('Class_Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataProcessing():\n",
    "\n",
    "    def __init__(self ,data:pd.core.frame.DataFrame , output:pd.core.series.Series , input_width:int, stockname:str):\n",
    "\n",
    "        self.stockname :str  = stockname \n",
    "        self.input_width : int = input_width\n",
    "        self.data :pd.core.frame.DataFrame = data\n",
    "        self.output : pd.core.series.Series = output\n",
    "        self.column_indices : list[str] = {name: i for i, name in enumerate(data.columns)}\n",
    "        self.num_features : int = data.shape[1]\n",
    "        \n",
    "        #slit into test and train data\n",
    "        n = len(data)\n",
    "\n",
    "        self.input_train_dataset = data[:int(0.90 * n)]\n",
    "        self.output_train_dataset = output[:int(0.90 * n)]\n",
    "\n",
    "\n",
    "        self.input_test_dataset = data[int(0.90 * n):]\n",
    "        self.output_test_dataset = output[int(0.90 * n):]\n",
    "\n",
    "\n",
    "        #reset indecies\n",
    "        self.input_test_dataset = self.input_test_dataset.reset_index()\n",
    "        self.input_test_dataset.pop('index')\n",
    "        \n",
    "        self.output_test_dataset = self.output_test_dataset.reset_index()\n",
    "        self.output_test_dataset = self.output_test_dataset['Class_Number']\n",
    "\n",
    "        #Normalizing The Data\n",
    "\n",
    "        self.input_train_std = self.input_train_dataset.std()  \n",
    "        self.input_train_mean = self.input_train_dataset.mean()\n",
    "        \n",
    "        self.input_train_dataset = (self.input_train_dataset - self.input_train_mean) / self.input_train_std\n",
    "        self.input_test_dataset = (self.input_test_dataset - self.input_train_mean) / self.input_train_std\n",
    "\n",
    "    def plot_normalized_data(self):\n",
    "        data_std = (self.data - self.input_train_mean) / self.input_train_std\n",
    "        data_std = data_std.melt(var_name='Column', value_name='Normalized')\n",
    "        plt.figure(figsize=(40, 12))\n",
    "        ax = sns.violinplot(x='Column', y='Normalized', data=data_std)\n",
    "        _ = ax.set_xticklabels(self.data.keys(), rotation=90)\n",
    "\n",
    "    def make_windows(self,input_data:pd.core.frame.DataFrame , output_data:pd.core.series.Series):\n",
    "        \n",
    "        window_input = []\n",
    "        window_output=[]\n",
    "\n",
    "        for i in range(self.input_width,len(input_data)):\n",
    "\n",
    "            window_input.append(input_data[i-self.input_width:i].reset_index())\n",
    "            \n",
    "            window_output.append(output_data[i])\n",
    "\n",
    "            window_input[-1].pop('index')\n",
    "            \n",
    "            #convert pd.DataFrame to numpy\n",
    "            window_input[-1]= window_input[-1].to_numpy() \n",
    "\n",
    "        #convert list to numpy\n",
    "        window_input = np.asarray(window_input)\n",
    "        window_output = np.asarray(window_output)\n",
    "\n",
    "        window_output = tf.one_hot(window_output,depth=2)\n",
    "\n",
    "        return window_input,window_output  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataProcessing(df,input_width=256,output=BUY_OR_SELL_NUMBER,stockname='sp500_with_Indicator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_window , output_window = data.make_windows(input_data=data.input_train_dataset ,output_data=data.output_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model,modelname,data:dataProcessing,input_window,output_window):\n",
    "    MAX_EPOCHS = 25\n",
    "\n",
    "    #check if path is available\n",
    "    path = f'models/{modelname}/{data.stockname}/tensorboard/logs/fit'\n",
    "    pathlib.Path(path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "    \n",
    "    log_dir =f'models/{modelname}/{data.stockname}/tensorboard/logs/fit/{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=[tf.metrics.BinaryAccuracy(),tf.metrics.BinaryCrossentropy()])\n",
    "\n",
    "    history = model.fit(x=input_window,y= output_window ,validation_split=0.1, epochs=MAX_EPOCHS,verbose=2,callbacks=[tensorboard_callback])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inputs = keras.layers.Input(shape=(256,13))\n",
    "reshape = Reshape((256,13,1))(inputs)\n",
    "cnn0 = keras.layers.Conv2D(filters=20,kernel_size=(1,13),activation='relu')(reshape)\n",
    "cnn1 = keras.layers.Conv2D(filters=20,kernel_size=(2,13),activation='relu')(reshape)\n",
    "cnn2 = keras.layers.Conv2D(filters=20,kernel_size=(4,13),activation='relu')(reshape)\n",
    "cnn3 = keras.layers.Conv2D(filters=20,kernel_size=(8,13),activation='relu')(reshape)\n",
    "cnn4 = keras.layers.Conv2D(filters=20,kernel_size=(16,13),activation='relu')(reshape)\n",
    "cnn5 = keras.layers.Conv2D(filters=20,kernel_size=(32,13),activation='relu')(reshape)\n",
    "cnn6 = keras.layers.Conv2D(filters=20,kernel_size=(64,13),activation='relu')(reshape)\n",
    "cnn7 = keras.layers.Conv2D(filters=20,kernel_size=(128,13),activation='relu')(reshape)\n",
    "cnn8 = keras.layers.Conv2D(filters=20,kernel_size=(256,13),activation='relu')(reshape)\n",
    "flatten0 = keras.layers.Flatten()(cnn0)\n",
    "flatten1 = keras.layers.Flatten()(cnn1)\n",
    "flatten2 = keras.layers.Flatten()(cnn2)\n",
    "flatten3 = keras.layers.Flatten()(cnn3)\n",
    "flatten4 = keras.layers.Flatten()(cnn4)\n",
    "flatten5 = keras.layers.Flatten()(cnn5)\n",
    "flatten6 = keras.layers.Flatten()(cnn6)\n",
    "flatten7 = keras.layers.Flatten()(cnn7)\n",
    "flatten8 = keras.layers.Flatten()(cnn8)\n",
    "concatinate = keras.layers.Concatenate()([flatten0,flatten1,flatten2,flatten3,flatten4,flatten5,flatten6,flatten7,flatten8])\n",
    "dense = keras.layers.Dense(256,activation='relu')(concatinate)\n",
    "output = keras.layers.Dense(2,activation= 'softmax')(dense)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(\n",
    "    inputs = inputs,\n",
    "    outputs = output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2310/2310 - 40s - loss: 0.6911 - binary_accuracy: 0.5311 - binary_crossentropy: 0.6911 - val_loss: 0.6918 - val_binary_accuracy: 0.5118 - val_binary_crossentropy: 0.6918 - 40s/epoch - 17ms/step\n",
      "Epoch 2/25\n",
      "2310/2310 - 37s - loss: 0.6912 - binary_accuracy: 0.5311 - binary_crossentropy: 0.6912 - val_loss: 0.6934 - val_binary_accuracy: 0.5118 - val_binary_crossentropy: 0.6934 - 37s/epoch - 16ms/step\n",
      "Epoch 3/25\n",
      "2310/2310 - 37s - loss: 0.6912 - binary_accuracy: 0.5311 - binary_crossentropy: 0.6912 - val_loss: 0.6941 - val_binary_accuracy: 0.5118 - val_binary_crossentropy: 0.6941 - 37s/epoch - 16ms/step\n",
      "Epoch 4/25\n",
      "2310/2310 - 36s - loss: 0.6912 - binary_accuracy: 0.5311 - binary_crossentropy: 0.6912 - val_loss: 0.6936 - val_binary_accuracy: 0.5118 - val_binary_crossentropy: 0.6936 - 36s/epoch - 16ms/step\n",
      "Epoch 5/25\n",
      "2310/2310 - 37s - loss: 0.6912 - binary_accuracy: 0.5311 - binary_crossentropy: 0.6912 - val_loss: 0.6935 - val_binary_accuracy: 0.5118 - val_binary_crossentropy: 0.6935 - 37s/epoch - 16ms/step\n",
      "Epoch 6/25\n",
      "2310/2310 - 37s - loss: 0.6912 - binary_accuracy: 0.5311 - binary_crossentropy: 0.6912 - val_loss: 0.6940 - val_binary_accuracy: 0.5118 - val_binary_crossentropy: 0.6940 - 37s/epoch - 16ms/step\n",
      "Epoch 7/25\n",
      "2310/2310 - 36s - loss: 0.6912 - binary_accuracy: 0.5311 - binary_crossentropy: 0.6912 - val_loss: 0.6938 - val_binary_accuracy: 0.5118 - val_binary_crossentropy: 0.6938 - 36s/epoch - 16ms/step\n",
      "Epoch 8/25\n",
      "2310/2310 - 36s - loss: 0.6912 - binary_accuracy: 0.5311 - binary_crossentropy: 0.6912 - val_loss: 0.6937 - val_binary_accuracy: 0.5118 - val_binary_crossentropy: 0.6937 - 36s/epoch - 15ms/step\n",
      "Epoch 9/25\n",
      "2310/2310 - 35s - loss: 0.6912 - binary_accuracy: 0.5311 - binary_crossentropy: 0.6912 - val_loss: 0.6939 - val_binary_accuracy: 0.5118 - val_binary_crossentropy: 0.6939 - 35s/epoch - 15ms/step\n",
      "Epoch 10/25\n",
      "2310/2310 - 35s - loss: 0.6912 - binary_accuracy: 0.5311 - binary_crossentropy: 0.6912 - val_loss: 0.6939 - val_binary_accuracy: 0.5118 - val_binary_crossentropy: 0.6939 - 35s/epoch - 15ms/step\n",
      "Epoch 11/25\n",
      "2310/2310 - 35s - loss: 0.6912 - binary_accuracy: 0.5311 - binary_crossentropy: 0.6912 - val_loss: 0.6938 - val_binary_accuracy: 0.5118 - val_binary_crossentropy: 0.6938 - 35s/epoch - 15ms/step\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2864/833135907.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompile_and_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmodelname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'secondcnn(22-03-11)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_window\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_window\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_window\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_window\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2864/3843615429.py\u001b[0m in \u001b[0;36mcompile_and_fit\u001b[1;34m(model, modelname, data, input_window, output_window)\u001b[0m\n\u001b[0;32m     15\u001b[0m                     metrics=[tf.metrics.BinaryAccuracy(),tf.metrics.BinaryCrossentropy()])\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_window\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0moutput_window\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fpp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fpp\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fpp\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fpp\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fpp\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fpp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fpp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fpp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fpp\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compile_and_fit(model=model , modelname='secondcnn(22-03-11)',data = data,input_window=input_window,output_window=output_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/secondcnn(22-03-11)/model.h5')\n",
    "# model = keras.models.load_model('models/firstcnn/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iw , ow = data.make_windows(input_data=data.input_test_dataset , output_data=tds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=model.predict(iw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_list = predicted.tolist()\n",
    "output_list = ow.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6397"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in range(len(predicted_list)):\n",
    "    if(predicted_list[i][0]>0.9 or predicted_list[i][1]>0.9):\n",
    "        counter+=1\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6397"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = []\n",
    "pred= []\n",
    "\n",
    "for index in range(len(predicted_list)):\n",
    "    \n",
    "    if(predicted_list[index][0]>0.9):\n",
    "        pred.append(predicted_list[index])\n",
    "        real.append(output_list[index])\n",
    "    \n",
    "    elif(predicted_list[index][1]>0.9):\n",
    "        pred.append(predicted_list[index])\n",
    "        real.append(output_list[index])\n",
    "\n",
    "len(real) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5049242"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tf.keras.metrics.BinaryAccuracy()\n",
    "m.update_state(y_true = real,y_pred = pred)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b0900fbe6dcf68ba8657d6a73781eea6c8e04d861aa42c88ba789e96c4944de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
