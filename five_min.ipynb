{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib as mpl\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import datetime\n",
                "import numpy as np\n",
                "import seaborn as sns\n",
                "import tensorflow as tf\n",
                "import pathlib\n",
                "from tensorflow import keras\n",
                "from keras.layers import Dense,Reshape,Flatten,Input,Conv2D,Concatenate,Lambda,BatchNormalization,ReLU,Conv1D,DepthwiseConv1D\n",
                "from keras.callbacks import TensorBoard , ModelCheckpoint\n",
                "import sklearn  \n",
                "import pickle\n",
                "\n",
                "# import wandb\n",
                "# from wandb.keras import WandbCallback\n",
                "# wandb.init(project=\"five-min-project\", entity=\"slick-team\")\n",
                "\n",
                "mpl.rcParams['figure.figsize'] = (12, 8)\n",
                "mpl.rcParams['axes.grid'] = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>RSI</th>\n",
                            "      <th>CCI</th>\n",
                            "      <th>STOCH</th>\n",
                            "      <th>STOCH_SIGNAL</th>\n",
                            "      <th>Boll_Percent</th>\n",
                            "      <th>WILL_R</th>\n",
                            "      <th>DON_CHIAN_pband</th>\n",
                            "      <th>ADX_Pos</th>\n",
                            "      <th>ADX_Neg</th>\n",
                            "      <th>Aroon</th>\n",
                            "      <th>CANDEL_UPPER_SHADOW</th>\n",
                            "      <th>CANDEL_BODY</th>\n",
                            "      <th>CANDEL_LOWER_SHADOOW</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>53.358846</td>\n",
                            "      <td>16.428880</td>\n",
                            "      <td>57.272727</td>\n",
                            "      <td>37.922351</td>\n",
                            "      <td>0.656014</td>\n",
                            "      <td>-42.727273</td>\n",
                            "      <td>0.614754</td>\n",
                            "      <td>20.198086</td>\n",
                            "      <td>20.061216</td>\n",
                            "      <td>-28.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>2.5</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>51.659869</td>\n",
                            "      <td>27.991899</td>\n",
                            "      <td>48.181818</td>\n",
                            "      <td>47.972028</td>\n",
                            "      <td>0.579344</td>\n",
                            "      <td>-51.818182</td>\n",
                            "      <td>0.532787</td>\n",
                            "      <td>19.483670</td>\n",
                            "      <td>19.351641</td>\n",
                            "      <td>-28.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>0.8</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>49.132736</td>\n",
                            "      <td>-13.260635</td>\n",
                            "      <td>34.545455</td>\n",
                            "      <td>46.666667</td>\n",
                            "      <td>0.445320</td>\n",
                            "      <td>-65.454545</td>\n",
                            "      <td>0.409836</td>\n",
                            "      <td>18.467570</td>\n",
                            "      <td>21.551741</td>\n",
                            "      <td>-28.0</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>-1.5</td>\n",
                            "      <td>0.9</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>45.460502</td>\n",
                            "      <td>-77.831342</td>\n",
                            "      <td>15.789474</td>\n",
                            "      <td>32.838915</td>\n",
                            "      <td>0.223298</td>\n",
                            "      <td>-84.210526</td>\n",
                            "      <td>0.221311</td>\n",
                            "      <td>17.521366</td>\n",
                            "      <td>23.316732</td>\n",
                            "      <td>-24.0</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>-2.3</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>51.862081</td>\n",
                            "      <td>-9.465111</td>\n",
                            "      <td>56.989247</td>\n",
                            "      <td>35.774725</td>\n",
                            "      <td>0.627301</td>\n",
                            "      <td>-43.010753</td>\n",
                            "      <td>0.532787</td>\n",
                            "      <td>18.911944</td>\n",
                            "      <td>21.167662</td>\n",
                            "      <td>-20.0</td>\n",
                            "      <td>0.2</td>\n",
                            "      <td>3.8</td>\n",
                            "      <td>0.6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>91516</th>\n",
                            "      <td>39.595103</td>\n",
                            "      <td>-97.218277</td>\n",
                            "      <td>20.886076</td>\n",
                            "      <td>15.089552</td>\n",
                            "      <td>0.176959</td>\n",
                            "      <td>-79.113924</td>\n",
                            "      <td>0.208861</td>\n",
                            "      <td>14.750090</td>\n",
                            "      <td>21.255647</td>\n",
                            "      <td>-36.0</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.3</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>91517</th>\n",
                            "      <td>43.307788</td>\n",
                            "      <td>-78.384883</td>\n",
                            "      <td>28.481013</td>\n",
                            "      <td>23.417722</td>\n",
                            "      <td>0.279226</td>\n",
                            "      <td>-71.518987</td>\n",
                            "      <td>0.284810</td>\n",
                            "      <td>13.800860</td>\n",
                            "      <td>19.887757</td>\n",
                            "      <td>-36.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>1.2</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>91518</th>\n",
                            "      <td>41.043835</td>\n",
                            "      <td>-80.791539</td>\n",
                            "      <td>22.151899</td>\n",
                            "      <td>23.839662</td>\n",
                            "      <td>0.237582</td>\n",
                            "      <td>-77.848101</td>\n",
                            "      <td>0.221519</td>\n",
                            "      <td>13.126965</td>\n",
                            "      <td>18.916639</td>\n",
                            "      <td>-36.0</td>\n",
                            "      <td>0.3</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>0.7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>91519</th>\n",
                            "      <td>39.487705</td>\n",
                            "      <td>-82.970358</td>\n",
                            "      <td>18.300654</td>\n",
                            "      <td>22.977855</td>\n",
                            "      <td>0.220795</td>\n",
                            "      <td>-81.699346</td>\n",
                            "      <td>0.177215</td>\n",
                            "      <td>12.471156</td>\n",
                            "      <td>19.220558</td>\n",
                            "      <td>-36.0</td>\n",
                            "      <td>0.8</td>\n",
                            "      <td>-0.7</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>91520</th>\n",
                            "      <td>48.499608</td>\n",
                            "      <td>-48.514528</td>\n",
                            "      <td>49.152542</td>\n",
                            "      <td>29.868365</td>\n",
                            "      <td>0.422300</td>\n",
                            "      <td>-50.847458</td>\n",
                            "      <td>0.367089</td>\n",
                            "      <td>15.085911</td>\n",
                            "      <td>17.566603</td>\n",
                            "      <td>-36.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>91521 rows × 13 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "             RSI        CCI      STOCH  STOCH_SIGNAL  Boll_Percent     WILL_R  \\\n",
                            "0      53.358846  16.428880  57.272727     37.922351      0.656014 -42.727273   \n",
                            "1      51.659869  27.991899  48.181818     47.972028      0.579344 -51.818182   \n",
                            "2      49.132736 -13.260635  34.545455     46.666667      0.445320 -65.454545   \n",
                            "3      45.460502 -77.831342  15.789474     32.838915      0.223298 -84.210526   \n",
                            "4      51.862081  -9.465111  56.989247     35.774725      0.627301 -43.010753   \n",
                            "...          ...        ...        ...           ...           ...        ...   \n",
                            "91516  39.595103 -97.218277  20.886076     15.089552      0.176959 -79.113924   \n",
                            "91517  43.307788 -78.384883  28.481013     23.417722      0.279226 -71.518987   \n",
                            "91518  41.043835 -80.791539  22.151899     23.839662      0.237582 -77.848101   \n",
                            "91519  39.487705 -82.970358  18.300654     22.977855      0.220795 -81.699346   \n",
                            "91520  48.499608 -48.514528  49.152542     29.868365      0.422300 -50.847458   \n",
                            "\n",
                            "       DON_CHIAN_pband    ADX_Pos    ADX_Neg  Aroon  CANDEL_UPPER_SHADOW  \\\n",
                            "0             0.614754  20.198086  20.061216  -28.0                  0.0   \n",
                            "1             0.532787  19.483670  19.351641  -28.0                  0.0   \n",
                            "2             0.409836  18.467570  21.551741  -28.0                  0.2   \n",
                            "3             0.221311  17.521366  23.316732  -24.0                  0.2   \n",
                            "4             0.532787  18.911944  21.167662  -20.0                  0.2   \n",
                            "...                ...        ...        ...    ...                  ...   \n",
                            "91516         0.208861  14.750090  21.255647  -36.0                  2.0   \n",
                            "91517         0.284810  13.800860  19.887757  -36.0                  1.0   \n",
                            "91518         0.221519  13.126965  18.916639  -36.0                  0.3   \n",
                            "91519         0.177215  12.471156  19.220558  -36.0                  0.8   \n",
                            "91520         0.367089  15.085911  17.566603  -36.0                  0.0   \n",
                            "\n",
                            "       CANDEL_BODY  CANDEL_LOWER_SHADOOW  \n",
                            "0              2.5                   0.5  \n",
                            "1             -1.0                   0.8  \n",
                            "2             -1.5                   0.9  \n",
                            "3             -2.3                   0.0  \n",
                            "4              3.8                   0.6  \n",
                            "...            ...                   ...  \n",
                            "91516          0.0                   0.3  \n",
                            "91517          1.2                   0.5  \n",
                            "91518         -1.0                   0.7  \n",
                            "91519         -0.7                   0.5  \n",
                            "91520          3.0                   0.5  \n",
                            "\n",
                            "[91521 rows x 13 columns]"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#GETTING DATA\n",
                "\n",
                "df = pd.read_csv('data/sp500_with_indicators.csv')\n",
                "df.pop('Unnamed: 0')\n",
                "date_time = pd.to_datetime(df.pop('Date'))\n",
                "timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
                "\n",
                "#Removing unnecessary columns\n",
                "\n",
                "CLOSE = df.pop('Close')\n",
                "OPEN = df.pop('Open') \n",
                "HIGH = df.pop('High') \n",
                "LOW = df.pop('Low') \n",
                "VOLUME = df.pop('Volume') \n",
                "SPREAD = df.pop('Spread')\n",
                "TICKVOL = df.pop('TickVol') \n",
                "BUY_OR_SELL = df.pop('Class')\n",
                "BUY_OR_SELL_NUMBER = df.pop('Class_Number')\n",
                "CANDEL_BODY = df.pop('Candel_Body')    \n",
                "CANDEL_UPPER_SHADOW = df.pop('Candel_Upper_Shadow')   \n",
                "CANDEL_LOWER_SHADOOW = df.pop('Candel_Lower_Shadow')   \n",
                "\n",
                "df['CANDEL_UPPER_SHADOW'] = CANDEL_UPPER_SHADOW\n",
                "df['CANDEL_BODY'] = CANDEL_BODY\n",
                "df['CANDEL_LOWER_SHADOOW'] = CANDEL_LOWER_SHADOOW\n",
                "\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "#DATA PROCESSING CLASS\n",
                "\n",
                "class DataProcessing():\n",
                "\n",
                "    def __init__(self ,data:pd.core.frame.DataFrame , output:pd.core.series.Series , input_width:int, stockname:str,\n",
                "                    min_max :bool =False,minimum:float=1.0 , maximum:float=1.0):\n",
                "        \"\"\"init method of our DataProcessing class\n",
                "\n",
                "        Args:\n",
                "            data (pd.core.frame.DataFrame): all of our data\n",
                "            output (pd.core.series.Series): all of our outputs\n",
                "            input_width (int): window size\n",
                "            stockname (str): stock name \n",
                "            min_max (bool, optional):  wether we want min_max scaling.Defaults to False.\n",
                "            minimum (float, optional): mininum of scaled data. Defaults to 1.0.\n",
                "            maximum (float, optional): maximum of scaled data. Defaults to 1.0.\n",
                "        \"\"\"\n",
                "        self.stockname :str  = stockname \n",
                "        self.input_width : int = input_width\n",
                "        self.data :pd.core.frame.DataFrame = data\n",
                "        self.output : pd.core.series.Series = output\n",
                "        self.column_indices : list[str] = {name: i for i, name in enumerate(data.columns)}\n",
                "        self.num_features : int = data.shape[1]\n",
                "        \n",
                "        self.data_mean = self.data.mean()\n",
                "        self.data_std = self.data.std()\n",
                "        #slit into test and train data\n",
                "        # n = len(data)\n",
                "\n",
                "        # self.input_train_dataset = data[:int(0.90 * n)]\n",
                "        # self.output_train_dataset = output[:int(0.90 * n)]\n",
                "\n",
                "\n",
                "        # self.input_test_dataset = data[int(0.90 * n):]\n",
                "        # self.output_test_dataset = output[int(0.90 * n):]\n",
                "\n",
                "\n",
                "        #reset indecies\n",
                "        # self.input_test_dataset = self.input_test_dataset.reset_index()\n",
                "        # self.input_test_dataset.pop(\"index\")\n",
                "        \n",
                "        # self.output_test_dataset = self.output_test_dataset.reset_index()\n",
                "        # self.output_test_dataset = self.output_test_dataset[\"Class_Number\"]\n",
                "\n",
                "        #Normalizing The Data\n",
                "\n",
                "        # self.input_train_dataset, self.input_train_std ,self.input_train_mean = normalize(self.input_train_dataset)\n",
                "        # self.input_test_dataset ,_,_ = normalize(self.input_test_dataset,data_std=self.input_train_std,data_mean=self.input_train_mean)\n",
                "\n",
                "\n",
                "        # self.input_train_std = self.input_train_dataset.std()  \n",
                "        # self.input_train_mean = self.input_train_dataset.mean()\n",
                "        \n",
                "        # self.input_train_dataset = (self.input_train_dataset - self.input_train_mean) / self.input_train_std\n",
                "        # self.input_test_dataset = (self.input_test_dataset - self.input_train_mean) / self.input_train_std\n",
                "\n",
                "        #Min max scaling \n",
                "\n",
                "        # if(min_max):\n",
                "        #     self.input_train_dataset = min_max_scaler(self.input_train_dataset,minimum,maximum)\n",
                "        #     self.input_test_dataset = min_max_scaler(self.input_test_dataset,minimum,maximum)\n",
                "            \n",
                "\n",
                "    def plot_normalized_data(self):\n",
                "        data_std = (self.data - self.data_mean) / self.data_std\n",
                "        data_std = data_std.melt(var_name=\"Column\", value_name=\"Normalized\")\n",
                "        plt.figure(figsize=(40, 12))\n",
                "        ax = sns.violinplot(x=\"Column\", y=\"Normalized\", data=data_std)\n",
                "        _ = ax.set_xticklabels(self.data.keys(), rotation=90)\n",
                "\n",
                "    def make_windows(self,input_data:pd.core.frame.DataFrame , output_data:pd.core.series.Series , convert_to_numpy:bool = True):\n",
                "        \n",
                "        \"\"\"making windows\n",
                "\n",
                "        Args:\n",
                "            input_data (pd.core.frame.DataFrame): input data\n",
                "            output_data (pd.core.series.Series): output data\n",
                "            convert_to_numpy (bool, optional): whether we want to convert our windows to numpy or not. Defaults to True.\n",
                "\n",
                "        Returns:\n",
                "            2 lists/numpy arrays: input windows and output windows\n",
                "        \"\"\"\n",
                "        \n",
                "        window_input = []\n",
                "        window_output=[]\n",
                "\n",
                "        for i in range(self.input_width,len(input_data)):\n",
                "\n",
                "            window_input.append(input_data[i-self.input_width:i].reset_index())\n",
                "            \n",
                "            window_output.append(output_data[i])\n",
                "\n",
                "            window_input[-1].pop(\"index\")\n",
                "            \n",
                "            #convert pd.DataFrame to numpy\n",
                "            window_input[-1]= window_input[-1].to_numpy() \n",
                "\n",
                "        #convert list to numpy\n",
                "\n",
                "        if(convert_to_numpy):\n",
                "            window_input = np.asarray(window_input)\n",
                "            window_output = np.asarray(window_output)\n",
                "\n",
                "            window_output = tf.one_hot(window_output,depth=2)\n",
                "\n",
                "        return window_input,window_output  \n",
                "\n",
                "\n",
                "def normalize(data:pd.core.frame.DataFrame,data_std=None,data_mean=None):\n",
                "    if(data_std is None):\n",
                "        data_std = data.std()\n",
                "    if(data_mean is None):\n",
                "        data_mean = data.mean()\n",
                "\n",
                "\n",
                "    data_normalized = (data-data_mean)/data_std\n",
                "\n",
                "    return data_normalized, data_std,data_mean\n",
                "    \n",
                "def min_max_scaler(data:pd.core.frame.DataFrame,minimum:float,maximum:float):\n",
                "    data_max = data.describe().transpose()[\"max\"]\n",
                "    data_min = data.describe().transpose()[\"min\"]\n",
                "    data_std = (data-data_min)/(data_max-data_min)\n",
                "    data_scaled = data_std*(abs(minimum)+maximum)+minimum\n",
                "    return data_scaled\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = DataProcessing(  data=df,\n",
                "                        output=BUY_OR_SELL_NUMBER,\n",
                "                        input_width=256,\n",
                "                        stockname=\"sp500_with_Indicator\",\n",
                "                        min_max=True,\n",
                "                        minimum=-1.0,\n",
                "                        maximum=1.0\n",
                "                        )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaled_data ,_,_=normalize(df)\n",
                "\n",
                "scaled_df = min_max_scaler(scaled_data,-1.,1.)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "#MAKE, SAVE, LOAD\n",
                "def make():\n",
                "    input_window , output_window = data.make_windows(   \n",
                "                                                    input_data=scaled_df,\n",
                "                                                    output_data=BUY_OR_SELL_NUMBER,\n",
                "                                                    convert_to_numpy=False\n",
                "                                                )\n",
                "    return input_window,output_window\n",
                "\n",
                "def save(input_window,output_window):\n",
                "    with open(\"data/windows/input_window.pickle\",\"wb\") as fp:\n",
                "        pickle.dump(input_window,fp)\n",
                "\n",
                "    with open('data/windows/output_window.pickle','wb') as fp:\n",
                "        pickle.dump(output_window,fp)\n",
                "\n",
                "\n",
                "def load():\n",
                "    with open('data/windows/input_window.pickle','rb') as fp:\n",
                "        input_window=pickle.load(fp)\n",
                "\n",
                "    with open('data/windows/output_window.pickle','rb') as fp:\n",
                "        output_window=pickle.load(fp)\n",
                "    return input_window,output_window\n",
                "\n",
                "# input_window,output_window=make()\n",
                "# save(input_window,output_window)\n",
                "# input_window,output_window=load()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "#MAKE, SAVE and LOAD train/test  \n",
                "def make_train_test(input_window,output_window):\n",
                "\n",
                "    test_input = []\n",
                "    test_output = []\n",
                "\n",
                "    test_input_24 = []\n",
                "    test_output_24 = []\n",
                "\n",
                "    random_indices = []\n",
                "\n",
                "    for j in range(200):\n",
                "\n",
                "        random_index=np.random.randint(0,len(input_window)-48)\n",
                "        random_indices.append(random_index)\n",
                "        inp = []\n",
                "        out = []\n",
                "\n",
                "        for i in range(48):\n",
                "            index=i+random_index\n",
                "            \n",
                "            inp.append(input_window.pop(index))\n",
                "            out.append(output_window.pop(index))\n",
                "\n",
                "        for i in range(24):\n",
                "            test_input_24.append(inp[i])\n",
                "            test_output_24.append(out[i])\n",
                "\n",
                "            test_input.append(inp[i+24])\n",
                "            test_output.append(out[i+24])\n",
                "\n",
                "\n",
                "    #CONVERT TO NUMPY\n",
                "    input_window = np.asarray(input_window)\n",
                "    output_window = np.asarray(output_window)\n",
                "    output_window = tf.one_hot(output_window,depth=2)\n",
                "\n",
                "    test_input = np.asarray(test_input)\n",
                "    test_output = np.asarray(test_output)\n",
                "    test_output = tf.one_hot(test_output,depth=2)\n",
                "\n",
                "    test_input_24 = np.asarray(test_input_24)\n",
                "    test_output_24 = np.asarray(test_output_24)\n",
                "    test_output_24 = tf.one_hot(test_output_24,depth=2)\n",
                "\n",
                "    return input_window,output_window,test_input,test_output,test_input_24,test_output_24,random_indices\n",
                "\n",
                "\n",
                "def save_train_test(input_window,output_window,test_input,test_output,test_input_24,test_output_24,random_indices):\n",
                "\n",
                "        with open('data/windows/train_data/input_window.pickle','wb') as fp:\n",
                "            pickle.dump(input_window,fp)\n",
                "\n",
                "        with open('data/windows/train_data/output_window.pickle','wb') as fp:\n",
                "            pickle.dump(output_window,fp)\n",
                "\n",
                "        with open('data/windows/test_data/test_input.pickle','wb') as fp:\n",
                "            pickle.dump(test_input,fp)\n",
                "\n",
                "        with open('data/windows/test_data/test_output.pickle','wb') as fp:\n",
                "            pickle.dump(test_output,fp)\n",
                "\n",
                "        with open('data/windows/test_data/test_input_24.pickle','wb') as fp:\n",
                "            pickle.dump(test_input_24,fp)\n",
                "\n",
                "        with open('data/windows/test_data/test_output_24.pickle','wb') as fp:\n",
                "            pickle.dump(test_output_24,fp)\n",
                "\n",
                "        with open('data/windows/test_data/random_indices.pickle','wb') as fp:\n",
                "            pickle.dump(random_indices,fp)\n",
                "\n",
                "\n",
                "def load_train_test():\n",
                "\n",
                "    with open('data/windows/train_data/input_window.pickle','rb') as fp:\n",
                "        input_window=pickle.load(fp)\n",
                "\n",
                "    with open('data/windows/train_data/output_window.pickle','rb') as fp:\n",
                "        output_window=pickle.load(fp)\n",
                "\n",
                "    with open('data/windows/test_data/test_input.pickle','rb') as fp:\n",
                "        test_input=pickle.load(fp)\n",
                "\n",
                "    with open('data/windows/test_data/test_output.pickle','rb') as fp:\n",
                "        test_output=pickle.load(fp)\n",
                "\n",
                "    with open('data/windows/test_data/test_input_24.pickle','rb') as fp:\n",
                "        test_input_24=pickle.load(fp)\n",
                "\n",
                "    with open('data/windows/test_data/test_output_24.pickle','rb') as fp:\n",
                "        test_output_24=pickle.load(fp)\n",
                "\n",
                "    with open('data/windows/test_data/random_indices.pickle','rb') as fp:\n",
                "        random_indices=pickle.load(fp)\n",
                "\n",
                "    return input_window,output_window,test_input,test_output,test_input_24,test_output_24,random_indices\n",
                "        \n",
                "# input_window,output_window,test_input,test_output,test_input_24,test_output_24,random_indices = make_train_test(input_window,output_window)\n",
                "# save_train_test(input_window,output_window,test_input,test_output,test_input_24,test_output_24,random_indices)\n",
                "input_window,output_window,test_input,test_output,test_input_24,test_output_24,random_indices = load_train_test()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compile_and_fit(model,modelname,data:DataProcessing,input_window,output_window ,modelcheckpoint:bool = False):\n",
                "    import os\n",
                "\n",
                "    MAX_EPOCHS = 10\n",
                "    # wandb.config = {\n",
                "    #         \"learning_rate\": 0.001,\n",
                "    #         \"epochs\": MAX_EPOCHS,\n",
                "    #         \"batch_size\": 64\n",
                "    #         }\n",
                "\n",
                "\n",
                "    #check if path is available\n",
                "    path = f'models/{modelname}/{data.stockname}/tensorboard/logs/fit'\n",
                "    pathlib.Path(path).mkdir(parents=True,exist_ok=True)\n",
                "\n",
                "    #tensorboard\n",
                "    log_dir =f'models/{modelname}/{data.stockname}/tensorboard/logs/fit/{datetime.datetime.now().strftime(\"(%Y-%m-%d)-(%H-%M-%S)\")}'\n",
                "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
                "\n",
                "    #modelcheckpoint\n",
                "    checkpoint_path = \"tmp/cp-{epoch:04d}.ckpt\"\n",
                "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
                "\n",
                "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
                "        filepath=checkpoint_path,\n",
                "        monitor='val_binary_accuracy',\n",
                "        verbose=1,\n",
                "        save_weights_only=True,\n",
                "        save_best_only=False\n",
                "    )\n",
                "\n",
                "    model.save_weights(checkpoint_path.format(epoch=0))\n",
                "\n",
                "\n",
                "    model.compile(loss='binary_crossentropy',\n",
                "                    optimizer='adam',\n",
                "                    metrics=[tf.metrics.BinaryAccuracy()])\n",
                "\n",
                "    if modelcheckpoint:\n",
                "        history = model.fit(    x=input_window,\n",
                "                                y= output_window,\n",
                "                                validation_data=(test_input,test_output),\n",
                "                                batch_size=64,\n",
                "                                shuffle=True,\n",
                "                                epochs=MAX_EPOCHS,\n",
                "                                verbose=2,\n",
                "                                callbacks=[tensorboard_callback,model_checkpoint_callback],\n",
                "                            )\n",
                "\n",
                "    else:\n",
                "        \n",
                "        history = model.fit(    \n",
                "                        x=input_window,\n",
                "                        y= output_window,\n",
                "                        validation_data=(test_input,test_output),\n",
                "                        batch_size=64,\n",
                "                        shuffle=True,\n",
                "                        epochs=MAX_EPOCHS,\n",
                "                        verbose=2,\n",
                "                        callbacks=[tensorboard_callback],\n",
                "                    )\n",
                "    \n",
                "    return history"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def convert_candel_to_1d_array(candels_reshape,filters):\n",
                "\n",
                "    conv2d_1 = Conv2D(filters=filters/1,kernel_size=(  4,3),strides=(2,1),name=\"conv2d_1\")(candels_reshape)\n",
                "    conv2d_2 = Conv2D(filters=filters/2,kernel_size=(  8,3),strides=(2,1),name=\"conv2d_2\")(candels_reshape)\n",
                "    conv2d_3 = Conv2D(filters=filters/3,kernel_size=( 16,3),strides=(2,1),name=\"conv2d_3\")(candels_reshape)\n",
                "    conv2d_4 = Conv2D(filters=filters/4,kernel_size=( 32,3),strides=(2,1),name=\"conv2d_4\")(candels_reshape)\n",
                "    conv2d_5 = Conv2D(filters=filters/5,kernel_size=( 64,3),strides=(2,1),name=\"conv2d_5\")(candels_reshape)\n",
                "    conv2d_6 = Conv2D(filters=filters/6,kernel_size=(128,3),strides=(2,1),name=\"conv2d_6\")(candels_reshape)\n",
                "\n",
                "    batch_norm_1 = BatchNormalization(name=\"batch_norm_1\")(conv2d_1)\n",
                "    batch_norm_2 = BatchNormalization(name=\"batch_norm_2\")(conv2d_2)\n",
                "    batch_norm_3 = BatchNormalization(name=\"batch_norm_3\")(conv2d_3)\n",
                "    batch_norm_4 = BatchNormalization(name=\"batch_norm_4\")(conv2d_4)\n",
                "    batch_norm_5 = BatchNormalization(name=\"batch_norm_5\")(conv2d_5)\n",
                "    batch_norm_6 = BatchNormalization(name=\"batch_norm_6\")(conv2d_6)\n",
                "\n",
                "    relu_1 = ReLU(name = \"relu_1\")(batch_norm_1)\n",
                "    relu_2 = ReLU(name = \"relu_2\")(batch_norm_2)\n",
                "    relu_3 = ReLU(name = \"relu_3\")(batch_norm_3)\n",
                "    relu_4 = ReLU(name = \"relu_4\")(batch_norm_4)\n",
                "    relu_5 = ReLU(name = \"relu_5\")(batch_norm_5)\n",
                "    relu_6 = ReLU(name = \"relu_6\")(batch_norm_6)\n",
                "\n",
                "    reshape_1 = Reshape(target_shape=(relu_1.shape[1],relu_1.shape[3]),name='reshape_1')(relu_1)\n",
                "    reshape_2 = Reshape(target_shape=(relu_2.shape[1],relu_2.shape[3]),name='reshape_2')(relu_2)\n",
                "    reshape_3 = Reshape(target_shape=(relu_3.shape[1],relu_3.shape[3]),name='reshape_3')(relu_3)\n",
                "    reshape_4 = Reshape(target_shape=(relu_4.shape[1],relu_4.shape[3]),name='reshape_4')(relu_4)\n",
                "    reshape_5 = Reshape(target_shape=(relu_5.shape[1],relu_5.shape[3]),name='reshape_5')(relu_5)\n",
                "    reshape_6 = Reshape(target_shape=(relu_6.shape[1],relu_6.shape[3]),name='reshape_6')(relu_6)\n",
                "\n",
                "    return reshape_1,reshape_2,reshape_3,reshape_4,reshape_5,reshape_6\n",
                "\n",
                "def one_stride_conv_block(reshape_1,reshape_2,reshape_3,reshape_4,reshape_5,reshape_6,filters , blockid:int):\n",
                "\n",
                "    depthwiseconv1d_1 = DepthwiseConv1D(kernel_size=  4 ,padding='same',name=f'depthconv1d_1_block{blockid}')(reshape_1)\n",
                "    depthwiseconv1d_2 = DepthwiseConv1D(kernel_size=  8 ,padding='same',name=f'depthconv1d_2_block{blockid}')(reshape_2)\n",
                "    depthwiseconv1d_3 = DepthwiseConv1D(kernel_size= 16 ,padding='same',name=f'depthconv1d_3_block{blockid}')(reshape_3)\n",
                "    depthwiseconv1d_4 = DepthwiseConv1D(kernel_size= 32 ,padding='same',name=f'depthconv1d_4_block{blockid}')(reshape_4)\n",
                "    depthwiseconv1d_5 = DepthwiseConv1D(kernel_size= 64 ,padding='same',name=f'depthconv1d_5_block{blockid}')(reshape_5)\n",
                "    depthwiseconv1d_6 = DepthwiseConv1D(kernel_size=128 ,padding='same',name=f'depthconv1d_6_block{blockid}')(reshape_6)\n",
                "\n",
                "    batch_norm_1 = BatchNormalization(name=f'batch_norm_1_1_block{blockid}')(depthwiseconv1d_1)\n",
                "    batch_norm_2 = BatchNormalization(name=f'batch_norm_1_2_block{blockid}')(depthwiseconv1d_2)\n",
                "    batch_norm_3 = BatchNormalization(name=f'batch_norm_1_3_block{blockid}')(depthwiseconv1d_3)\n",
                "    batch_norm_4 = BatchNormalization(name=f'batch_norm_1_4_block{blockid}')(depthwiseconv1d_4)\n",
                "    batch_norm_5 = BatchNormalization(name=f'batch_norm_1_5_block{blockid}')(depthwiseconv1d_5)\n",
                "    batch_norm_6 = BatchNormalization(name=f'batch_norm_1_6_block{blockid}')(depthwiseconv1d_6)\n",
                "\n",
                "    relu_1 = ReLU(name=f'relu_1_1_block{blockid}')(batch_norm_1)\n",
                "    relu_2 = ReLU(name=f'relu_1_2_block{blockid}')(batch_norm_2)\n",
                "    relu_3 = ReLU(name=f'relu_1_3_block{blockid}')(batch_norm_3)\n",
                "    relu_4 = ReLU(name=f'relu_1_4_block{blockid}')(batch_norm_4)\n",
                "    relu_5 = ReLU(name=f'relu_1_5_block{blockid}')(batch_norm_5)\n",
                "    relu_6 = ReLU(name=f'relu_1_6_block{blockid}')(batch_norm_6)\n",
                "\n",
                "    conv1d_1 = Conv1D(filters=filters/1,kernel_size=  4 ,padding='same',name=f'conv1d_1_block{blockid}')(relu_1)\n",
                "    conv1d_2 = Conv1D(filters=filters/2,kernel_size=  8 ,padding='same',name=f'conv1d_2_block{blockid}')(relu_2)\n",
                "    conv1d_3 = Conv1D(filters=filters/3,kernel_size= 16 ,padding='same',name=f'conv1d_3_block{blockid}')(relu_3)\n",
                "    conv1d_4 = Conv1D(filters=filters/4,kernel_size= 32 ,padding='same',name=f'conv1d_4_block{blockid}')(relu_4)\n",
                "    conv1d_5 = Conv1D(filters=filters/5,kernel_size= 64 ,padding='same',name=f'conv1d_5_block{blockid}')(relu_5)\n",
                "    conv1d_6 = Conv1D(filters=filters/6,kernel_size=128 ,padding='same',name=f'conv1d_6_block{blockid}')(relu_6)\n",
                "\n",
                "    batch_norm_1 = BatchNormalization(name=f'batch_norm_2_1_block{blockid}')(conv1d_1)\n",
                "    batch_norm_2 = BatchNormalization(name=f'batch_norm_2_2_block{blockid}')(conv1d_2)\n",
                "    batch_norm_3 = BatchNormalization(name=f'batch_norm_2_3_block{blockid}')(conv1d_3)\n",
                "    batch_norm_4 = BatchNormalization(name=f'batch_norm_2_4_block{blockid}')(conv1d_4)\n",
                "    batch_norm_5 = BatchNormalization(name=f'batch_norm_2_5_block{blockid}')(conv1d_5)\n",
                "    batch_norm_6 = BatchNormalization(name=f'batch_norm_2_6_block{blockid}')(conv1d_6)\n",
                "\n",
                "    relu_1 = ReLU(name=f'relu_2_1_block{blockid}')(batch_norm_1)\n",
                "    relu_2 = ReLU(name=f'relu_2_2_block{blockid}')(batch_norm_2)\n",
                "    relu_3 = ReLU(name=f'relu_2_3_block{blockid}')(batch_norm_3)\n",
                "    relu_4 = ReLU(name=f'relu_2_4_block{blockid}')(batch_norm_4)\n",
                "    relu_5 = ReLU(name=f'relu_2_5_block{blockid}')(batch_norm_5)\n",
                "    relu_6 = ReLU(name=f'relu_2_6_block{blockid}')(batch_norm_6)\n",
                "\n",
                "    return relu_1,relu_2,relu_3,relu_4,relu_5,relu_6\n",
                "\n",
                "def two_stride_conv_block(relu_1,relu_2,relu_3,relu_4,relu_5,relu_6,filters:int,blockid:int):\n",
                "\n",
                "    depthwiseconv1d_1 = DepthwiseConv1D(kernel_size=  4 ,padding='same',strides= 2,name=f'depthconv1d_1_block{blockid}')(relu_1)\n",
                "    depthwiseconv1d_2 = DepthwiseConv1D(kernel_size=  8 ,padding='same',strides= 2,name=f'depthconv1d_2_block{blockid}')(relu_2)\n",
                "    depthwiseconv1d_3 = DepthwiseConv1D(kernel_size= 16 ,padding='same',strides= 2,name=f'depthconv1d_3_block{blockid}')(relu_3)\n",
                "    depthwiseconv1d_4 = DepthwiseConv1D(kernel_size= 32 ,padding='same',strides= 2,name=f'depthconv1d_4_block{blockid}')(relu_4)\n",
                "    depthwiseconv1d_5 = DepthwiseConv1D(kernel_size= 64 ,padding='same',strides= 2,name=f'depthconv1d_5_block{blockid}')(relu_5)\n",
                "    depthwiseconv1d_6 = DepthwiseConv1D(kernel_size=128 ,padding='same',strides= 2,name=f'depthconv1d_6_block{blockid}')(relu_6)\n",
                "\n",
                "    batch_norm_1 = BatchNormalization(name=f'batch_norm_1_1_block{blockid}')(depthwiseconv1d_1)\n",
                "    batch_norm_2 = BatchNormalization(name=f'batch_norm_1_2_block{blockid}')(depthwiseconv1d_2)\n",
                "    batch_norm_3 = BatchNormalization(name=f'batch_norm_1_3_block{blockid}')(depthwiseconv1d_3)\n",
                "    batch_norm_4 = BatchNormalization(name=f'batch_norm_1_4_block{blockid}')(depthwiseconv1d_4)\n",
                "    batch_norm_5 = BatchNormalization(name=f'batch_norm_1_5_block{blockid}')(depthwiseconv1d_5)\n",
                "    batch_norm_6 = BatchNormalization(name=f'batch_norm_1_6_block{blockid}')(depthwiseconv1d_6)\n",
                "\n",
                "    relu_1 = ReLU(name=f'relu_1_1_block{blockid}')(batch_norm_1)\n",
                "    relu_2 = ReLU(name=f'relu_1_2_block{blockid}')(batch_norm_2)\n",
                "    relu_3 = ReLU(name=f'relu_1_3_block{blockid}')(batch_norm_3)\n",
                "    relu_4 = ReLU(name=f'relu_1_4_block{blockid}')(batch_norm_4)\n",
                "    relu_5 = ReLU(name=f'relu_1_5_block{blockid}')(batch_norm_5)\n",
                "    relu_6 = ReLU(name=f'relu_1_6_block{blockid}')(batch_norm_6)\n",
                "\n",
                "    conv1d_1 = Conv1D(filters=filters/1,kernel_size=  4 ,padding='same',name=f'conv1d_1_block{blockid}')(relu_1)\n",
                "    conv1d_2 = Conv1D(filters=filters/2,kernel_size=  8 ,padding='same',name=f'conv1d_2_block{blockid}')(relu_2)\n",
                "    conv1d_3 = Conv1D(filters=filters/3,kernel_size= 16 ,padding='same',name=f'conv1d_3_block{blockid}')(relu_3)\n",
                "    conv1d_4 = Conv1D(filters=filters/4,kernel_size= 32 ,padding='same',name=f'conv1d_4_block{blockid}')(relu_4)\n",
                "    conv1d_5 = Conv1D(filters=filters/5,kernel_size= 64 ,padding='same',name=f'conv1d_5_block{blockid}')(relu_5)\n",
                "    conv1d_6 = Conv1D(filters=filters/6,kernel_size=128 ,padding='same',name=f'conv1d_6_block{blockid}')(relu_6)\n",
                "\n",
                "    batch_norm_1 = BatchNormalization(name=f'batch_norm_2_1_block{blockid}')(conv1d_1)\n",
                "    batch_norm_2 = BatchNormalization(name=f'batch_norm_2_2_block{blockid}')(conv1d_2)\n",
                "    batch_norm_3 = BatchNormalization(name=f'batch_norm_2_3_block{blockid}')(conv1d_3)\n",
                "    batch_norm_4 = BatchNormalization(name=f'batch_norm_2_4_block{blockid}')(conv1d_4)\n",
                "    batch_norm_5 = BatchNormalization(name=f'batch_norm_2_5_block{blockid}')(conv1d_5)\n",
                "    batch_norm_6 = BatchNormalization(name=f'batch_norm_2_6_block{blockid}')(conv1d_6)\n",
                "\n",
                "    relu_1 = ReLU(name=f'relu_2_1_block{blockid}')(batch_norm_1)\n",
                "    relu_2 = ReLU(name=f'relu_2_2_block{blockid}')(batch_norm_2)\n",
                "    relu_3 = ReLU(name=f'relu_2_3_block{blockid}')(batch_norm_3)\n",
                "    relu_4 = ReLU(name=f'relu_2_4_block{blockid}')(batch_norm_4)\n",
                "    relu_5 = ReLU(name=f'relu_2_5_block{blockid}')(batch_norm_5)\n",
                "    relu_6 = ReLU(name=f'relu_2_6_block{blockid}')(batch_norm_6)\n",
                "\n",
                "    return relu_1,relu_2,relu_3,relu_4,relu_5,relu_6\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "#CANDEL MODEL\n",
                "\n",
                "input_layer = Input(shape=(256,3))\n",
                "reshaped_candels = Reshape(target_shape=(256,3,1),name=\"reshape_0\")(input_layer)\n",
                "#Converting candels into 1d arrays\n",
                "\n",
                "reshape_1,reshape_2,reshape_3,reshape_4,reshape_5,reshape_6 = convert_candel_to_1d_array(\n",
                "                                                                                            candels_reshape=reshaped_candels,\n",
                "                                                                                            filters=32\n",
                "                                                                                        )\n",
                "\n",
                "#Block1 with strides = 1, shape sizes of: 127 , 125 , 121 , 113 , 97 , 65 \n",
                "\n",
                "relu_1,relu_2,relu_3,relu_4,relu_5,relu_6 = one_stride_conv_block(\n",
                "                                                                    reshape_1,\n",
                "                                                                    reshape_2,\n",
                "                                                                    reshape_3,\n",
                "                                                                    reshape_4,\n",
                "                                                                    reshape_5,\n",
                "                                                                    reshape_6,\n",
                "                                                                    filters=32,\n",
                "                                                                    blockid=1\n",
                "                                                                )\n",
                "\n",
                "\n",
                "#Block 2 with stride = 2, shape sizes of: 64 , 63 , 61 , 57 , 49 , 33\n",
                "relu_1,relu_2,relu_3,relu_4,relu_5,relu_6 = two_stride_conv_block(\n",
                "                                                                    relu_1,\n",
                "                                                                    relu_2,\n",
                "                                                                    relu_3,\n",
                "                                                                    relu_4,\n",
                "                                                                    relu_5,\n",
                "                                                                    relu_6,\n",
                "                                                                    filters=64,\n",
                "                                                                    blockid=2\n",
                "                                                                )\n",
                "\n",
                "#Block 3 with stride = 2, shape sizes of: 32 , 32, 31, 29, 25 , 17\n",
                "relu_1,relu_2,relu_3,relu_4,relu_5,relu_6 = two_stride_conv_block(\n",
                "                                                                    relu_1,\n",
                "                                                                    relu_2,\n",
                "                                                                    relu_3,\n",
                "                                                                    relu_4,\n",
                "                                                                    relu_5,\n",
                "                                                                    relu_6,\n",
                "                                                                    filters=128,\n",
                "                                                                    blockid=3\n",
                "                                                                )\n",
                "\n",
                "#Block 4 with stride = 2, shape sizes of: 16, 16, 16, 15, 13,  9\n",
                "relu_1,relu_2,relu_3,relu_4,relu_5,relu_6 = two_stride_conv_block(\n",
                "                                                                    relu_1,\n",
                "                                                                    relu_2,\n",
                "                                                                    relu_3,\n",
                "                                                                    relu_4,\n",
                "                                                                    relu_5,\n",
                "                                                                    relu_6,\n",
                "                                                                    filters=256,\n",
                "                                                                    blockid=4\n",
                "                                                                )\n",
                "\n",
                "#Block 5 with stride = 2, shape sizes of: 8, 8, 8, 8, 7, 5\n",
                "relu_1,relu_2,relu_3,relu_4,relu_5,relu_6 = two_stride_conv_block(\n",
                "                                                                    relu_1,\n",
                "                                                                    relu_2,\n",
                "                                                                    relu_3,\n",
                "                                                                    relu_4,\n",
                "                                                                    relu_5,\n",
                "                                                                    relu_6,\n",
                "                                                                    filters=256,\n",
                "                                                                    blockid=5\n",
                "                                                                )\n",
                "\n",
                "\n",
                "global_avg_pool_1 = keras.layers.GlobalAveragePooling1D(name=\"global_avg_pool_1\")(relu_1)\n",
                "global_avg_pool_2 = keras.layers.GlobalAveragePooling1D(name=\"global_avg_pool_2\")(relu_2)\n",
                "global_avg_pool_3 = keras.layers.GlobalAveragePooling1D(name=\"global_avg_pool_3\")(relu_3)\n",
                "global_avg_pool_4 = keras.layers.GlobalAveragePooling1D(name=\"global_avg_pool_4\")(relu_4)\n",
                "global_avg_pool_5 = keras.layers.GlobalAveragePooling1D(name=\"global_avg_pool_5\")(relu_5)\n",
                "global_avg_pool_6 = keras.layers.GlobalAveragePooling1D(name=\"global_avg_pool_6\")(relu_6)\n",
                "\n",
                "\n",
                "candel_model = keras.Model(\n",
                "                        inputs = input_layer,\n",
                "\n",
                "                        outputs = [\n",
                "                                    global_avg_pool_1,\n",
                "                                    global_avg_pool_2,\n",
                "                                    global_avg_pool_3,\n",
                "                                    global_avg_pool_4,\n",
                "                                    global_avg_pool_5,\n",
                "                                    global_avg_pool_6\n",
                "                                ]\n",
                "                    )\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "#INDICATOR MODEL\n",
                "\n",
                "input_layer = Input(shape=(256,10))\n",
                "\n",
                "relu_1,relu_2,relu_3,relu_4,relu_5,relu_6 = one_stride_conv_block(\n",
                "                                                                    input_layer,\n",
                "                                                                    input_layer,\n",
                "                                                                    input_layer,\n",
                "                                                                    input_layer,\n",
                "                                                                    input_layer,\n",
                "                                                                    input_layer,\n",
                "                                                                    filters=32,\n",
                "                                                                    blockid=10\n",
                "                                                                )\n",
                "\n",
                "relu_1,relu_2,relu_3,relu_4,relu_5,relu_6 = one_stride_conv_block(\n",
                "                                                                    relu_1,\n",
                "                                                                    relu_2,\n",
                "                                                                    relu_3,\n",
                "                                                                    relu_4,\n",
                "                                                                    relu_5,\n",
                "                                                                    relu_6,\n",
                "                                                                    filters=32,\n",
                "                                                                    blockid=11\n",
                "                                                                )\n",
                "\n",
                "\n",
                "#Block 2 with stride = 2, shape sizes of: 64 , 63 , 61 , 57 , 49 , 33\n",
                "relu_1,relu_2,relu_3,relu_4,relu_5,relu_6 = two_stride_conv_block(\n",
                "                                                                    relu_1,\n",
                "                                                                    relu_2,\n",
                "                                                                    relu_3,\n",
                "                                                                    relu_4,\n",
                "                                                                    relu_5,\n",
                "                                                                    relu_6,\n",
                "                                                                    filters=64,\n",
                "                                                                    blockid=12\n",
                "                                                                )\n",
                "\n",
                "#Block 3 with stride = 2, shape sizes of: 32 , 32, 31, 29, 25 , 17\n",
                "relu_1,relu_2,relu_3,relu_4,relu_5,relu_6 = two_stride_conv_block(\n",
                "                                                                    relu_1,\n",
                "                                                                    relu_2,\n",
                "                                                                    relu_3,\n",
                "                                                                    relu_4,\n",
                "                                                                    relu_5,\n",
                "                                                                    relu_6,\n",
                "                                                                    filters=128,\n",
                "                                                                    blockid=13\n",
                "                                                                )\n",
                "\n",
                "#Block 4 with stride = 2, shape sizes of: 16, 16, 16, 15, 13,  9\n",
                "relu_1,relu_2,relu_3,relu_4,relu_5,relu_6 = two_stride_conv_block(\n",
                "                                                                    relu_1,\n",
                "                                                                    relu_2,\n",
                "                                                                    relu_3,\n",
                "                                                                    relu_4,\n",
                "                                                                    relu_5,\n",
                "                                                                    relu_6,\n",
                "                                                                    filters=256,\n",
                "                                                                    blockid=14\n",
                "                                                                )\n",
                "\n",
                "#Block 5 with stride = 2, shape sizes of: 8, 8, 8, 8, 7, 5\n",
                "relu_1,relu_2,relu_3,relu_4,relu_5,relu_6 = two_stride_conv_block(\n",
                "                                                                    relu_1,\n",
                "                                                                    relu_2,\n",
                "                                                                    relu_3,\n",
                "                                                                    relu_4,\n",
                "                                                                    relu_5,\n",
                "                                                                    relu_6,\n",
                "                                                                    filters=256,\n",
                "                                                                    blockid=15\n",
                "                                                                )\n",
                "\n",
                "\n",
                "global_avg_pool_1 = keras.layers.GlobalAveragePooling1D(name=\"global_avg_pool_indicator_1\")(relu_1)\n",
                "global_avg_pool_2 = keras.layers.GlobalAveragePooling1D(name=\"global_avg_pool_indicator_2\")(relu_2)\n",
                "global_avg_pool_3 = keras.layers.GlobalAveragePooling1D(name=\"global_avg_pool_indicator_3\")(relu_3)\n",
                "global_avg_pool_4 = keras.layers.GlobalAveragePooling1D(name=\"global_avg_pool_indicator_4\")(relu_4)\n",
                "global_avg_pool_5 = keras.layers.GlobalAveragePooling1D(name=\"global_avg_pool_indicator_5\")(relu_5)\n",
                "global_avg_pool_6 = keras.layers.GlobalAveragePooling1D(name=\"global_avg_pool_indicator_6\")(relu_6)\n",
                "\n",
                "\n",
                "indicator_model = keras.Model(\n",
                "                        inputs = input_layer,\n",
                "                        outputs = [\n",
                "                                    global_avg_pool_1,\n",
                "                                    global_avg_pool_2,\n",
                "                                    global_avg_pool_3,\n",
                "                                    global_avg_pool_4,\n",
                "                                    global_avg_pool_5,\n",
                "                                    global_avg_pool_6\n",
                "                                ]\n",
                "                    )\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "#MODEL\n",
                "input_layer = Input(shape=(256,13))\n",
                "candels = Lambda(lambda x: x[:,:,-3:])(input_layer)\n",
                "indicators = Lambda(lambda x: x[:,:,:-3])(input_layer)\n",
                "\n",
                "gap_candel_1,gap_candel_2,gap_candel_3,gap_candel_4,gap_candel_5,gap_candel_6=candel_model(candels)\n",
                "gap_indicator_1,gap_indicator_2,gap_indicator_3,gap_indicator_4,gap_indicator_5,gap_indicator_6 = indicator_model(indicators)\n",
                "\n",
                "\n",
                "concatinate = Concatenate()([   gap_candel_1,\n",
                "                                gap_candel_2,\n",
                "                                gap_candel_3,\n",
                "                                gap_candel_4,\n",
                "                                gap_candel_5,\n",
                "                                gap_candel_6,\n",
                "                                gap_indicator_1,\n",
                "                                gap_indicator_2,\n",
                "                                gap_indicator_3,\n",
                "                                gap_indicator_4,\n",
                "                                gap_indicator_5,\n",
                "                                gap_indicator_6]\n",
                ")\n",
                "\n",
                "dense01 = Dense(1024 , activation='relu')(concatinate)\n",
                "output = Dense(2 ,activation='softmax')(dense01)\n",
                "\n",
                "model = keras.Model(\n",
                "    inputs = input_layer,\n",
                "    outputs = output\n",
                ")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# indicator_model.summary()\n",
                "# tf.keras.utils.plot_model(model ,'model.png')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "#name of the model \n",
                "name = \"6_(functional)_(22_04_02)\"\n",
                "\n",
                "# compile_and_fit(model=model , modelname=name,\n",
                "#                 data = data,input_window=input_window,\n",
                "#                 output_window=output_window,modelcheckpoint=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model.save(f'models/{name}/model.h5')\n",
                "\n",
                "# model = keras.models.load_model(f'models/{name}/model.h5')\n",
                "# model.load_weights(f\"models/{name}/modelcheckpoint/cp-0003.ckpt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "data": {"text/plain": ["0.649375"]},
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "m = tf.keras.metrics.BinaryAccuracy()\n",
                "m.update_state(y_true = test_output,y_pred = predicted2)\n",
                "m.result().numpy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# a1 = np.ones((3,3),dtype=np.int8) + 0\n",
                "# a2 = np.ones((3,3),dtype=np.int8) + 1\n",
                "# a3 = np.ones((3,3),dtype=np.int8) + 2\n",
                "# a4 = np.ones((3,3),dtype=np.int8) + 3\n",
                "\n",
                "# a11 = np.ones((3,3),dtype=np.int8) * 10\n",
                "# a12 = np.ones((3,3),dtype=np.int8) * 20\n",
                "# a13 = np.ones((3,3),dtype=np.int8) * 30\n",
                "# a14 = np.ones((3,3),dtype=np.int8) * 40\n",
                "\n",
                "# inputs = np.array([a1,a2,a3,a4])\n",
                "# outputs = np.array([a11,a12,a13,a14])\n",
                "# a , b = sklearn.utils.shuffle(inputs,outputs)\n",
                "# print(f'{[a123 for a123 in a]},{[b123 for b123 in b]}')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "#PLOTING DISTRIBUTION OF PREDICTIONS ON DIFFERENT EPOCHS\n",
                "\n",
                "\n",
                "predictions = []\n",
                "\n",
                "NUMBER_OF_EPOCHS=10\n",
                "model = keras.Model(\n",
                "                        inputs = input_layer,\n",
                "                        outputs = output\n",
                "                    )\n",
                "for i in range(NUMBER_OF_EPOCHS):\n",
                "\n",
                "    model.load_weights(f\"models/{name}/modelcheckpoint/cp-00{i+1:02d}.ckpt\")\n",
                "    prediction = model.predict(test_input)\n",
                "    predictions.append(prediction)\n",
                "\n",
                "#PLOT\n",
                "mpl.rcParams['axes.grid'] = False\n",
                "mpl.rcParams['figure.figsize'] = (22, 40)\n",
                "fig, axes=plt.subplots(10,2)\n",
                "\n",
                "for i,value in enumerate(predictions):\n",
                "    for j in range(2):\n",
                "        if(j==0):\n",
                "            axes[i,j].hist(value[:,1],bins=50, label=f'epoch{i+1:02d}')\n",
                "            axes[i,j].legend(loc='best')\n",
                "\n",
                "        else:\n",
                "            axes[i,j].hist(test_output[:,1].numpy(),bins=50, label=f'epoch{i+1:02d}')\n",
                "            axes[i,j].legend(loc='best')\n",
                "\n",
                "            \n"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "2b0900fbe6dcf68ba8657d6a73781eea6c8e04d861aa42c88ba789e96c4944de"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 ('tensor')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {"name": "ipython", "version": 3},
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
