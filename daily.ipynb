{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential,activations\n",
    "from keras.layers import Dense,LSTM,Reshape,Dropout,InputLayer,Flatten,Input,BatchNormalization\n",
    "from keras.callbacks import TensorBoard , ModelCheckpoint\n",
    "import pathlib\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 8)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sp100_indicator_1990.csv')\n",
    "df.pop('Unnamed: 0')\n",
    "\n",
    "date_time = pd.to_datetime(df.pop('Date'),\n",
    "                           format='%Y.%m.%d')\n",
    "\n",
    "timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "df['Time']= timestamp_s\n",
    "# timestamp_s = timestamp_s.map(pd.Timestamp.normalize)\n",
    "# timestamp_s = pd.Timestamp(date_time)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "# timestamp_s\n",
    "# year = 365.2425\n",
    "# df['1 Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "# df['1 Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twoYear = year * 2\n",
    "# threeYear = year * 3\n",
    "# fourYear = year *4\n",
    "# fiveYear = year *5\n",
    "# sixYear = year *6\n",
    "# sevenYear = year *7\n",
    "# eightYear = year *8\n",
    "# nineYear = year *9\n",
    "# tenYear = year *10\n",
    "# twentyYear = year *20\n",
    "# fortyYear = year * 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df['2 Year sin'] = np.sin(timestamp_s * (2 * np.pi / twoYear))\n",
    "# df['2 Year cos'] = np.cos(timestamp_s * (2 * np.pi / twoYear))\n",
    "# df['3 Year sin'] = np.sin(timestamp_s * (2 * np.pi / threeYear))\n",
    "# df['3 Year cos'] = np.cos(timestamp_s * (2 * np.pi / threeYear))\n",
    "# df['4 Year sin'] = np.sin(timestamp_s * (2 * np.pi / fourYear))\n",
    "# df['4 Year cos'] = np.cos(timestamp_s * (2 * np.pi / fourYear))\n",
    "# df['5 Year sin'] = np.sin(timestamp_s * (2 * np.pi / fiveYear))\n",
    "# df['5 Year cos'] = np.cos(timestamp_s * (2 * np.pi / fiveYear))\n",
    "# df['6 Year sin'] = np.sin(timestamp_s * (2 * np.pi / sixYear))\n",
    "# df['6 Year cos'] = np.cos(timestamp_s * (2 * np.pi / sixYear))\n",
    "# df['7 Year sin'] = np.sin(timestamp_s * (2 * np.pi / sevenYear))\n",
    "# df['7 Year cos'] = np.cos(timestamp_s * (2 * np.pi / sevenYear))\n",
    "# df['8 Year sin'] = np.sin(timestamp_s * (2 * np.pi / eightYear))\n",
    "# df['8 Year cos'] = np.cos(timestamp_s * (2 * np.pi / eightYear))\n",
    "# df['9 Year sin'] = np.sin(timestamp_s * (2 * np.pi / nineYear))\n",
    "# df['9 Year cos'] = np.cos(timestamp_s * (2 * np.pi / nineYear))\n",
    "# df['10 Year sin'] = np.sin(timestamp_s * (2 * np.pi / tenYear))\n",
    "# df['10 Year cos'] = np.cos(timestamp_s * (2 * np.pi / tenYear))\n",
    "# df['20 Year sin'] = np.sin(timestamp_s * (2 * np.pi / twentyYear))\n",
    "# df['20 Year cos'] = np.cos(timestamp_s * (2 * np.pi / twentyYear))\n",
    "# df['40 Year sin'] = np.sin(timestamp_s * (2 * np.pi / fortyYear))\n",
    "# df['40 Year cos'] = np.cos(timestamp_s * (2 * np.pi / fortyYear))\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_cols = ['1 Year sin','2 Year sin','3 Year sin','4 Year sin','5 Year sin','6 Year sin','7 Year sin','8 Year sin','9 Year sin','10 Year sin','20 Year sin','40 Year sin']\n",
    "# plot_features = df[plot_cols]\n",
    "# plot_features.index = date_time\n",
    "# _ = plot_features.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fft = tf.signal.rfft(df['Close'])\n",
    "# f_per_dataset = np.arange(0, len(fft))\n",
    "\n",
    "# n_samples_h = len(df['Close'])\n",
    "\n",
    "# hours_per_year = 365.2524\n",
    "# years_per_dataset = n_samples_h/(hours_per_year)\n",
    "\n",
    "# f_per_year = f_per_dataset/years_per_dataset\n",
    "# plt.step(f_per_year, np.abs(fft))\n",
    "# plt.xscale('log')\n",
    "\n",
    "# _ = plt.xlabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataProcessing():\n",
    "\n",
    "    def __init__(self ,data,input_width ,prediction_days , label_columns , stockname):\n",
    "\n",
    "        self.stockname = stockname\n",
    "        self.input_width = input_width\n",
    "        self.prediction_days = prediction_days\n",
    "        self.label_columns = label_columns\n",
    "        self.data = data\n",
    "\n",
    "        self.column_indices = {name: i for i, name in enumerate(data.columns)}\n",
    "        self.num_features = data.shape[1]\n",
    "        \n",
    "        #slit into test,validation and train data\n",
    "        n = len(data)\n",
    "        self.train_dataset = data[:int(0.95 * n)]\n",
    "        # self.val_dataset = data[-200:-100]\n",
    "        self.test_dataset = data[int(0.95 * n):]\n",
    "        \n",
    "        #reset indecies\n",
    "\n",
    "        # self.val_dataset = self.val_dataset.reset_index()\n",
    "        # self.val_dataset.pop('index')\n",
    "        self.test_dataset = self.test_dataset.reset_index()\n",
    "        self.test_dataset.pop('index')\n",
    "        \n",
    "\n",
    "        #Normalizing The Data\n",
    "\n",
    "        self.train_std = self.train_dataset.std()  \n",
    "        self.train_mean = self.train_dataset.mean()\n",
    "        \n",
    "        self.train_dataset = (self.train_dataset - self.train_mean) / self.train_std\n",
    "        # self.val_dataset = (self.val_dataset - self.train_mean) / self.train_std\n",
    "        self.test_dataset = (self.test_dataset - self.train_mean) / self.train_std\n",
    "\n",
    "    def plot_normalized_data(self):\n",
    "        data_std = (self.data - self.train_mean) / self.train_std\n",
    "        data_std = data_std.melt(var_name='Column', value_name='Normalized')\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        ax = sns.violinplot(x='Column', y='Normalized', data=data_std)\n",
    "        _ = ax.set_xticklabels(self.data.keys(), rotation=90)\n",
    "\n",
    "    def make_windows(self,data:pd.core.frame.DataFrame):\n",
    "        \n",
    "        window_input = []\n",
    "        window_output=[]\n",
    "\n",
    "        for i in range(self.input_width,len(data)-self.prediction_days):\n",
    "\n",
    "            \n",
    "            window_input.append(data[i-self.input_width:i].reset_index())\n",
    "            window_output.append(data[self.label_columns][i:i+self.prediction_days].reset_index())\n",
    "\n",
    "            window_input[-1].pop('index')\n",
    "            window_output[-1].pop('index')\n",
    "            \n",
    "            #convert pd.DataFrame to numpy\n",
    "            window_input[-1]= window_input[-1].to_numpy() \n",
    "            window_output[-1]= window_output[-1].to_numpy() \n",
    "\n",
    "        #convert list to numpy\n",
    "        window_input = np.asarray(window_input)\n",
    "        window_output = np.asarray(window_output)\n",
    "\n",
    "        return window_input,window_output  \n",
    "\n",
    "    def test(self, model,test_data):\n",
    "\n",
    "        x_test , y_test = self.make_windows(test_data)\n",
    "\n",
    "        predicted_prices=model.predict(x_test)\n",
    "\n",
    "        for i in range(len(self.label_columns)):\n",
    "            predicted_prices[:,:,i]=(predicted_prices[:,:,i]*self.train_std[self.label_columns[i]])+self.train_mean[self.label_columns[i]]\n",
    "            y_test[:,:,i]=(y_test[:,:,i]*self.train_std[self.label_columns[i]])+self.train_mean[self.label_columns[i]]        \n",
    "\n",
    "        return predicted_prices , y_test\n",
    "        \n",
    "\n",
    "    # def test(self,model,test_data):\n",
    "\n",
    "    #     predicted_prices=model.predict(test_data)\n",
    "\n",
    "    #     for i in range(len(self.label_columns)):\n",
    "    #         predicted_prices[:,:,i]=(predicted_prices[:,:,i]*self.train_std[self.label_columns[i]])+self.train_mean[self.label_columns[i]]\n",
    "    #         y_test[:,:,i]=(y_test[:,:,i]*self.train_std[self.label_columns[i]])+self.train_mean[self.label_columns[i]]        \n",
    "\n",
    "    #     return predicted_prices , y_test\n",
    "        \n",
    "\n",
    "\n",
    "    def plot_and_saveCSV(self,model,modelname,predicted,real):\n",
    "\n",
    "        #check if path is available\n",
    "        path = f'./models/{modelname}/{self.stockname}/figures'\n",
    "        pathlib.Path(path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "        # pd.DataFrame(predicted).to_csv(f'models/{modelname}/{self.stockname}/predicted.csv')\n",
    "        # pd.DataFrame(real).to_csv(f'models/{modelname}/{self.stockname}/real.csv')\n",
    "\n",
    "        for i in range(len(real)):\n",
    "                \n",
    "            plt.plot(real[i,:,:], color=\"black\",label=f\"real\", marker='o', ms=10)\n",
    "            plt.plot(predicted[i,:,:], color=\"green\",label=f\"predicted\", marker='o', ms=10)\n",
    "\n",
    "            plt.savefig(f'models/{modelname}/{self.stockname}/figures/fig-{i+1}.png')\n",
    "            plt.clf()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                train_df, val_df, test_df,label_columns=None):\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                                enumerate(train_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])\n",
    "\n",
    "\n",
    "    def split_window(self, features):   \n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n",
    "        inputs, labels = self.example\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        for n in range(max_n):\n",
    "            plt.subplot(max_n, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [normed]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                    label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "                label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                        edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "            if model is not None:\n",
    "                predictions = model(inputs)\n",
    "                plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                            marker='X', edgecolors='k', label='Predictions',\n",
    "                            c='#ff7f0e', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "                plt.legend()\n",
    "\n",
    "        plt.xlabel('Time [h]')\n",
    "\n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=128,)\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "\n",
    "    @property\n",
    "    def example(self):\n",
    "        # \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "        result = getattr(self, '_example', None)\n",
    "        if result is None:\n",
    "        # No example batch was found, so get one from the `.train` dataset\n",
    "            result = next(iter(self.train))\n",
    "        # And cache it for next time\n",
    "            self._example = result\n",
    "        return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model,modelname,data:dataProcessing,window:WindowGenerator):\n",
    "    MAX_EPOCHS = 50\n",
    "\n",
    "    #check if path is available\n",
    "    path = f'models/{modelname}/{data.stockname}/tensorboard/logs/fit'\n",
    "    pathlib.Path(path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "    filepath = f'models/{modelname}/{data.stockname}'\n",
    "    \n",
    "    model_checkpoint_callback= tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath, monitor='loss', verbose=0, save_best_only=True,\n",
    "        save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "        options=None\n",
    "    )\n",
    "\n",
    "    log_dir =f'models/{modelname}/{data.stockname}/tensorboard/logs/fit/{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    metrics=[tf.metrics.MeanAbsoluteError(),tf.metrics.MeanAbsolutePercentageError()])\n",
    "\n",
    "    history = model.fit(window , epochs=MAX_EPOCHS,verbose=1,callbacks=[tensorboard_callback,model_checkpoint_callback])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataProcessing(df,input_width=60,prediction_days=1,label_columns=['Close'],stockname='sp100_with_Indicator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = WindowGenerator(  \n",
    "                        input_width=data.input_width,\n",
    "                        shift=data.prediction_days,\n",
    "                        label_width=1,\n",
    "                        train_df=data.train_dataset,\n",
    "                        val_df=None,\n",
    "                        test_df=data.test_dataset,\n",
    "                        label_columns=['Close']\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iw , ow = data.make_windows(data.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitures = data.num_features\n",
    "days= data.input_width\n",
    "\n",
    "test_model = Sequential()\n",
    "\n",
    "test_model.add(LSTM(units=fitures, input_shape = (days,fitures)))\n",
    "test_model.add(Dense(1000,activation=activations.elu))\n",
    "\n",
    "test_model.add(Flatten())\n",
    "test_model.add(Dense(units=1))\n",
    "test_model.add(Reshape([1,1]))\n",
    "test_model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history= compile_and_fit(\n",
    "                            model=test_model,\n",
    "                            modelname='test_model',\n",
    "                            data=data,\n",
    "                            window = wg.train\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_T ,real = data.make_windows(data.test_dataset)\n",
    "predictions = test_model.predict(input_T)\n",
    "\n",
    "list_a = [i for i in real[:,0,0]]\n",
    "\n",
    "list_real = [i*data.train_std['Close']+data.train_mean['Close'] for i in list_a]\n",
    "\n",
    "list_a = [i for i in predictions[:,0,0]]\n",
    "\n",
    "list_predict = [i*data.train_std['Close']+data.train_mean['Close'] for i in list_a]\n",
    "\n",
    "plt.plot(list_real, color=\"black\",label=f\"real\", marker='o', ms=1)\n",
    "plt.plot(list_predict, color=\"green\",label=f\"predicted\", marker='o', ms=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b0900fbe6dcf68ba8657d6a73781eea6c8e04d861aa42c88ba789e96c4944de"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tensor': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
