{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                train_df, val_df, test_df,label_columns=None):\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                                enumerate(train_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])\n",
    "\n",
    "\n",
    "    def split_window(self, features):   \n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n",
    "        inputs, labels = self.example\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        for n in range(max_n):\n",
    "            plt.subplot(max_n, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [normed]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                    label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "                label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                        edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "            if model is not None:\n",
    "                predictions = model(inputs)\n",
    "                plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                            marker='X', edgecolors='k', label='Predictions',\n",
    "                            c='#ff7f0e', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "                plt.legend()\n",
    "\n",
    "        plt.xlabel('Time [h]')\n",
    "\n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32,)\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "\n",
    "    @property\n",
    "    def example(self):\n",
    "        # \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "        result = getattr(self, '_example', None)\n",
    "        if result is None:\n",
    "        # No example batch was found, so get one from the `.train` dataset\n",
    "            result = next(iter(self.train))\n",
    "        # And cache it for next time\n",
    "            self._example = result\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting the weights and stuff\n",
    "\n",
    "# plt.bar(x = range(len(train_df.columns)),\n",
    "#         height=linear.layers[0].kernel[:,0].numpy())\n",
    "# axis = plt.gca()\n",
    "# axis.set_xticks(range(len(train_df.columns)))\n",
    "# _ = axis.set_xticklabels(train_df.columns, rotation=90)\n",
    "\n",
    "# lstm \n",
    "\"\"\"inputs = tf.random.normal([2, 3, 4])\n",
    "lstm = tf.keras.layers.LSTM(units=5 ,return_sequences=True)\n",
    "\n",
    "output = lstm(inputs)\n",
    "\n",
    "output\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    Dense_Model_3,\n",
    "    show_shapes=True,\n",
    "    show_dtype=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=True,\n",
    "    dpi=96,\n",
    "    layer_range=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel = tf.keras.Sequential()\n",
    "testmodel.add(LSTM(units=300, return_sequences=True , input_shape =(60,30)))\n",
    "testmodel.add(Dropout(0.1))\n",
    "testmodel.add(LSTM(units=720, return_sequences=True))\n",
    "testmodel.add(Dropout(0.1))\n",
    "testmodel.add(LSTM(units=360))\n",
    "testmodel.add(Dense(units=30, activation='linear'))\n",
    "testmodel.add(Reshape([10,3]))\n",
    "\n",
    "history = compile_and_fit(testmodel,'testmodel',data,input_window,output_widow)\n",
    "testmodel.save(f'models/testmodel/{data.stockname}/testmodel.h5')\n",
    "\n",
    "predicted , real = data.test(testmodel , data.test_dataset)\n",
    "data.plot_and_saveCSV(testmodel,'testmodel',predicted=predicted,real=real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        Reshape((1,1800),input_shape=(60,30)),\n",
    "        Dense(1800,activation='relu'),\n",
    "        Dense(2400,activation='relu'),\n",
    "        Dense(3000,activation='relu'),\n",
    "        Dense(500,activation='relu'),\n",
    "        Dense(30 ,activation='linear'),\n",
    "        Reshape((10,3)),\n",
    "    ]\n",
    ")\n",
    "history = compile_and_fit(dense_model_1,'dense_model_1',data,window_input=input_window,window_output=output_widow)\n",
    "predicted , real = data.test(dense_model_1 , data.test_dataset)\n",
    "data.plot_and_saveCSV(dense_model_1,'dense_model_1',predicted=predicted,real=real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model_2 = Sequential()\n",
    "\n",
    "dense_model_2.add(Dense(1800 , activation='relu',input_shape=(60,30)))\n",
    "dense_model_2.add(Flatten())\n",
    "dense_model_2.add(Dense(1200 , activation='relu'))\n",
    "dense_model_2.add(Dense(600 , activation='relu'))\n",
    "dense_model_2.add(Dense(300 , activation='relu'))\n",
    "dense_model_2.add(Dense(200 , activation='relu'))\n",
    "dense_model_2.add(Dense(300 , activation='relu'))\n",
    "dense_model_2.add(Dense(400 , activation='relu'))\n",
    "dense_model_2.add(Dense(500 , activation='relu'))\n",
    "dense_model_2.add(Dense(600 , activation='relu'))\n",
    "dense_model_2.add(Dense(1000 , activation='relu'))\n",
    "dense_model_2.add(Dense(10 , activation='linear'))\n",
    "dense_model_2.add(Reshape((10,1)))\n",
    "\n",
    "dense_model_2.summary()\n",
    "history = compile_and_fit(dense_model_2,'dense_model_2',data,window_input=input_window,window_output=output_widow)\n",
    "predicted , real = data.test(dense_model_2 , data.test_dataset)\n",
    "data.plot_and_saveCSV(dense_model_2,'dense_model_2',predicted=predicted,real=real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dense_Model_3 = Sequential()\n",
    "\n",
    "Dense_Model_3.add(Dense(30,activation=activations.linear,input_shape=(60,30),name='input'))\n",
    "Dense_Model_3.add(Dense(100,activation=activations.softmax))\n",
    "Dense_Model_3.add(Flatten())\n",
    "Dense_Model_3.add(Dense(2000,activation=activations.softmax))\n",
    "Dense_Model_3.add(Dense(2000,activation=activations.elu))\n",
    "Dense_Model_3.add(Dense(3000,activation=activations.elu))\n",
    "Dense_Model_3.add(Dense(4000,activation=activations.elu))\n",
    "Dense_Model_3.add(Dense(5000,activation=activations.elu))\n",
    "Dense_Model_3.add(Dense(6000,activation=activations.elu))\n",
    "Dense_Model_3.add(Dense(7000,activation=activations.elu))\n",
    "Dense_Model_3.add(Dense(10,activation=activations.linear))\n",
    "Dense_Model_3.add(Reshape((10,1)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dense_Model_3.summary()\n",
    "history = compile_and_fit(Dense_Model_3,'Dense_Model_3',data,window_input=input_window,window_output=output_widow)\n",
    "predicted , real = data.test(Dense_Model_3 , data.test_dataset)\n",
    "data.plot_and_saveCSV(Dense_Model_3,'Dense_Model_3',predicted=predicted,real=real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_STEPS=10\n",
    "num_features = 1\n",
    "multi_linear_model = tf.keras.Sequential([\n",
    "    # Take the last time-step.\n",
    "    # Shape [batch, time, features] => [batch, 1, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
    "    # Shape => [batch, 1, out_steps*features]\n",
    "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
    "                          kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = input_window.shape[2]\n",
    "\n",
    "\n",
    "class FeedBack(tf.keras.Model):\n",
    "    def __init__(self, units, out_steps):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
    "        # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(num_features)\n",
    "\n",
    "    def warmup(self, inputs):\n",
    "        # inputs.shape => (batch, time, features)\n",
    "        # x.shape => (batch, lstm_units)\n",
    "        x, *state = self.lstm_rnn(inputs)\n",
    "\n",
    "        # predictions.shape => (batch, features)\n",
    "        prediction = self.dense(x)\n",
    "        return prediction, state  \n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "        predictions = []\n",
    "        # Initialize the LSTM state.\n",
    "        prediction, state = self.warmup(inputs)\n",
    "\n",
    "        # Insert the first prediction.\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        # Run the rest of the prediction steps.\n",
    "        for n in range(1, self.out_steps):\n",
    "        # Use the last prediction as input.\n",
    "            x = prediction\n",
    "            # Execute one lstm step.\n",
    "            x, state = self.lstm_cell(x, states=state,\n",
    "                                        training=training)\n",
    "            # Convert the lstm output to a prediction.\n",
    "            prediction = self.dense(x)\n",
    "            # Add the prediction to the output.\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        # predictions.shape => (time, batch, features)\n",
    "        predictions = tf.stack(predictions)\n",
    "        # predictions.shape => (batch, time, features)\n",
    "        predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "        return predictions  \n",
    "\n",
    "\n",
    "feedback_model = FeedBack(units=32, out_steps=10)\n",
    "\n",
    "history = compile_and_fit(feedback_model, 'feedback_model',data=data,window_input=input_window,window_output=output_widow)\n",
    "# feedback_model.save(f'models/feedback_model/{data.stockname}/feedback_model')\n",
    "predicted , real = data.test(feedback_model , data.test_dataset)\n",
    "data.plot_and_saveCSV(feedback_model,'feedback_model',predicted=predicted,real=real)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10824/2069914842.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# x = iter([\"apple\", \"banana\", \"cherry\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = iter([\"apple\", \"banana\", \"cherry\"])\n",
    "x\n",
    "print(next(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new shit\n",
    "input_layer = Input(shape=(256,13))\n",
    "\n",
    "candels = Lambda(lambda x: x[:,:,-3:])(input_layer)\n",
    "indicators = Lambda(lambda x: x[:,:,:-3])(input_layer)\n",
    "\n",
    "\n",
    "candels_reshape = Reshape(target_shape=(256,3,1))(candels)\n",
    "#Converting candels into 1d arrays\n",
    "\n",
    "reshape_1,reshape_2,reshape_3,reshape_4,reshape_5,reshape_6 = convert_candel_to_1d_array(candels_reshape=candels_reshape)\n",
    "\n",
    "conv2d_1 = Conv2D(filters=32,kernel_size=(  4,3),strides=(2,1))(candels_reshape)\n",
    "conv2d_2 = Conv2D(filters=32,kernel_size=(  8,3),strides=(2,1))(candels_reshape)\n",
    "conv2d_3 = Conv2D(filters=32,kernel_size=( 16,3),strides=(2,1))(candels_reshape)\n",
    "conv2d_4 = Conv2D(filters=32,kernel_size=( 32,3),strides=(2,1))(candels_reshape)\n",
    "conv2d_5 = Conv2D(filters=32,kernel_size=( 64,3),strides=(2,1))(candels_reshape)\n",
    "conv2d_6 = Conv2D(filters=32,kernel_size=(128,3),strides=(2,1))(candels_reshape)\n",
    "\n",
    "batch_norm_1 = BatchNormalization()(conv2d_1)\n",
    "batch_norm_2 = BatchNormalization()(conv2d_2)\n",
    "batch_norm_3 = BatchNormalization()(conv2d_3)\n",
    "batch_norm_4 = BatchNormalization()(conv2d_4)\n",
    "batch_norm_5 = BatchNormalization()(conv2d_5)\n",
    "batch_norm_6 = BatchNormalization()(conv2d_6)\n",
    "\n",
    "relu_1 = ReLU()(batch_norm_1)\n",
    "relu_2 = ReLU()(batch_norm_2)\n",
    "relu_3 = ReLU()(batch_norm_3)\n",
    "relu_4 = ReLU()(batch_norm_4)\n",
    "relu_5 = ReLU()(batch_norm_5)\n",
    "relu_6 = ReLU()(batch_norm_6)\n",
    "\n",
    "reshape_1 = Reshape(target_shape=(relu_1.shape[1],relu_1.shape[3]))(relu_1)\n",
    "reshape_2 = Reshape(target_shape=(relu_2.shape[1],relu_2.shape[3]))(relu_2)\n",
    "reshape_3 = Reshape(target_shape=(relu_3.shape[1],relu_3.shape[3]))(relu_3)\n",
    "reshape_4 = Reshape(target_shape=(relu_4.shape[1],relu_4.shape[3]))(relu_4)\n",
    "reshape_5 = Reshape(target_shape=(relu_5.shape[1],relu_5.shape[3]))(relu_5)\n",
    "reshape_6 = Reshape(target_shape=(relu_6.shape[1],relu_6.shape[3]))(relu_6)\n",
    "\n",
    "#Block1 with min size: 65 -------------------------------------------------------------\n",
    "\n",
    "depthwiseconv1d_1 = DepthwiseConv1D(kernel_size=  4 ,padding='same')(reshape_1)\n",
    "depthwiseconv1d_2 = DepthwiseConv1D(kernel_size=  8 ,padding='same')(reshape_2)\n",
    "depthwiseconv1d_3 = DepthwiseConv1D(kernel_size= 16 ,padding='same')(reshape_3)\n",
    "depthwiseconv1d_4 = DepthwiseConv1D(kernel_size= 32 ,padding='same')(reshape_4)\n",
    "depthwiseconv1d_5 = DepthwiseConv1D(kernel_size= 64 ,padding='same')(reshape_5)\n",
    "depthwiseconv1d_6 = DepthwiseConv1D(kernel_size=128 ,padding='same')(reshape_6)\n",
    "\n",
    "batch_norm_1 = BatchNormalization()(depthwiseconv1d_1)\n",
    "batch_norm_2 = BatchNormalization()(depthwiseconv1d_2)\n",
    "batch_norm_3 = BatchNormalization()(depthwiseconv1d_3)\n",
    "batch_norm_4 = BatchNormalization()(depthwiseconv1d_4)\n",
    "batch_norm_5 = BatchNormalization()(depthwiseconv1d_5)\n",
    "batch_norm_6 = BatchNormalization()(depthwiseconv1d_6)\n",
    "\n",
    "relu_1 = ReLU()(batch_norm_1)\n",
    "relu_2 = ReLU()(batch_norm_2)\n",
    "relu_3 = ReLU()(batch_norm_3)\n",
    "relu_4 = ReLU()(batch_norm_4)\n",
    "relu_5 = ReLU()(batch_norm_5)\n",
    "relu_6 = ReLU()(batch_norm_6)\n",
    "\n",
    "conv1d_1 = Conv1D(filters=32,kernel_size=  4 ,padding='same')(relu_1)\n",
    "conv1d_2 = Conv1D(filters=32,kernel_size=  8 ,padding='same')(relu_2)\n",
    "conv1d_3 = Conv1D(filters=32,kernel_size= 16 ,padding='same')(relu_3)\n",
    "conv1d_4 = Conv1D(filters=32,kernel_size= 32 ,padding='same')(relu_4)\n",
    "conv1d_5 = Conv1D(filters=32,kernel_size= 64 ,padding='same')(relu_5)\n",
    "conv1d_6 = Conv1D(filters=32,kernel_size=128 ,padding='same')(relu_6)\n",
    "\n",
    "batch_norm_1 = BatchNormalization()(conv1d_1)\n",
    "batch_norm_2 = BatchNormalization()(conv1d_2)\n",
    "batch_norm_3 = BatchNormalization()(conv1d_3)\n",
    "batch_norm_4 = BatchNormalization()(conv1d_4)\n",
    "batch_norm_5 = BatchNormalization()(conv1d_5)\n",
    "batch_norm_6 = BatchNormalization()(conv1d_6)\n",
    "\n",
    "relu_1 = ReLU()(batch_norm_1)\n",
    "relu_2 = ReLU()(batch_norm_2)\n",
    "relu_3 = ReLU()(batch_norm_3)\n",
    "relu_4 = ReLU()(batch_norm_4)\n",
    "relu_5 = ReLU()(batch_norm_5)\n",
    "relu_6 = ReLU()(batch_norm_6)\n",
    "\n",
    "#Block 2 with min size : 33 -----------------------------------------------------------\n",
    "\n",
    "depthwiseconv1d_1 = DepthwiseConv1D(kernel_size=  4 ,padding='same',strides= 2)(relu_1)\n",
    "depthwiseconv1d_2 = DepthwiseConv1D(kernel_size=  8 ,padding='same',strides= 2)(relu_2)\n",
    "depthwiseconv1d_3 = DepthwiseConv1D(kernel_size= 16 ,padding='same',strides= 2)(relu_3)\n",
    "depthwiseconv1d_4 = DepthwiseConv1D(kernel_size= 32 ,padding='same',strides= 2)(relu_4)\n",
    "depthwiseconv1d_5 = DepthwiseConv1D(kernel_size= 64 ,padding='same',strides= 2)(relu_5)\n",
    "depthwiseconv1d_6 = DepthwiseConv1D(kernel_size=128 ,padding='same',strides= 2)(relu_6)\n",
    "\n",
    "batch_norm_1 = BatchNormalization()(depthwiseconv1d_1)\n",
    "batch_norm_2 = BatchNormalization()(depthwiseconv1d_2)\n",
    "batch_norm_3 = BatchNormalization()(depthwiseconv1d_3)\n",
    "batch_norm_4 = BatchNormalization()(depthwiseconv1d_4)\n",
    "batch_norm_5 = BatchNormalization()(depthwiseconv1d_5)\n",
    "batch_norm_6 = BatchNormalization()(depthwiseconv1d_6)\n",
    "\n",
    "relu_1 = ReLU()(batch_norm_1)\n",
    "relu_2 = ReLU()(batch_norm_2)\n",
    "relu_3 = ReLU()(batch_norm_3)\n",
    "relu_4 = ReLU()(batch_norm_4)\n",
    "relu_5 = ReLU()(batch_norm_5)\n",
    "relu_6 = ReLU()(batch_norm_6)\n",
    "\n",
    "conv1d_1 = Conv1D(filters=64,kernel_size=  4 ,padding='same')(relu_1)\n",
    "conv1d_2 = Conv1D(filters=64,kernel_size=  8 ,padding='same')(relu_2)\n",
    "conv1d_3 = Conv1D(filters=64,kernel_size= 16 ,padding='same')(relu_3)\n",
    "conv1d_4 = Conv1D(filters=64,kernel_size= 32 ,padding='same')(relu_4)\n",
    "conv1d_5 = Conv1D(filters=64,kernel_size= 64 ,padding='same')(relu_5)\n",
    "conv1d_6 = Conv1D(filters=64,kernel_size=128 ,padding='same')(relu_6)\n",
    "\n",
    "batch_norm_1 = BatchNormalization()(conv1d_1)\n",
    "batch_norm_2 = BatchNormalization()(conv1d_2)\n",
    "batch_norm_3 = BatchNormalization()(conv1d_3)\n",
    "batch_norm_4 = BatchNormalization()(conv1d_4)\n",
    "batch_norm_5 = BatchNormalization()(conv1d_5)\n",
    "batch_norm_6 = BatchNormalization()(conv1d_6)\n",
    "\n",
    "relu_1 = ReLU()(batch_norm_1)\n",
    "relu_2 = ReLU()(batch_norm_2)\n",
    "relu_3 = ReLU()(batch_norm_3)\n",
    "relu_4 = ReLU()(batch_norm_4)\n",
    "relu_5 = ReLU()(batch_norm_5)\n",
    "relu_6 = ReLU()(batch_norm_6)\n",
    "\n",
    "#Block 2 with min size : 17 ------------------------------------------------------------------\n",
    "\n",
    "depthwiseconv1d_1 = DepthwiseConv1D(kernel_size=  4 ,padding='same',strides= 2)(relu_1)\n",
    "depthwiseconv1d_2 = DepthwiseConv1D(kernel_size=  8 ,padding='same',strides= 2)(relu_2)\n",
    "depthwiseconv1d_3 = DepthwiseConv1D(kernel_size= 16 ,padding='same',strides= 2)(relu_3)\n",
    "depthwiseconv1d_4 = DepthwiseConv1D(kernel_size= 32 ,padding='same',strides= 2)(relu_4)\n",
    "depthwiseconv1d_5 = DepthwiseConv1D(kernel_size= 64 ,padding='same',strides= 2)(relu_5)\n",
    "depthwiseconv1d_6 = DepthwiseConv1D(kernel_size=128 ,padding='same',strides= 2)(relu_6)\n",
    "\n",
    "batch_norm_1 = BatchNormalization()(depthwiseconv1d_1)\n",
    "batch_norm_2 = BatchNormalization()(depthwiseconv1d_2)\n",
    "batch_norm_3 = BatchNormalization()(depthwiseconv1d_3)\n",
    "batch_norm_4 = BatchNormalization()(depthwiseconv1d_4)\n",
    "batch_norm_5 = BatchNormalization()(depthwiseconv1d_5)\n",
    "batch_norm_6 = BatchNormalization()(depthwiseconv1d_6)\n",
    "\n",
    "relu_1 = ReLU()(batch_norm_1)\n",
    "relu_2 = ReLU()(batch_norm_2)\n",
    "relu_3 = ReLU()(batch_norm_3)\n",
    "relu_4 = ReLU()(batch_norm_4)\n",
    "relu_5 = ReLU()(batch_norm_5)\n",
    "relu_6 = ReLU()(batch_norm_6)\n",
    "\n",
    "conv1d_1 = Conv1D(filters=128,kernel_size=  4 ,padding='same')(relu_1)\n",
    "conv1d_2 = Conv1D(filters=128,kernel_size=  8 ,padding='same')(relu_2)\n",
    "conv1d_3 = Conv1D(filters=128,kernel_size= 16 ,padding='same')(relu_3)\n",
    "conv1d_4 = Conv1D(filters=128,kernel_size= 32 ,padding='same')(relu_4)\n",
    "conv1d_5 = Conv1D(filters=128,kernel_size= 64 ,padding='same')(relu_5)\n",
    "conv1d_6 = Conv1D(filters=128,kernel_size=128 ,padding='same')(relu_6)\n",
    "\n",
    "batch_norm_1 = BatchNormalization()(conv1d_1)\n",
    "batch_norm_2 = BatchNormalization()(conv1d_2)\n",
    "batch_norm_3 = BatchNormalization()(conv1d_3)\n",
    "batch_norm_4 = BatchNormalization()(conv1d_4)\n",
    "batch_norm_5 = BatchNormalization()(conv1d_5)\n",
    "batch_norm_6 = BatchNormalization()(conv1d_6)\n",
    "\n",
    "relu_1 = ReLU()(batch_norm_1)\n",
    "relu_2 = ReLU()(batch_norm_2)\n",
    "relu_3 = ReLU()(batch_norm_3)\n",
    "relu_4 = ReLU()(batch_norm_4)\n",
    "relu_5 = ReLU()(batch_norm_5)\n",
    "relu_6 = ReLU()(batch_norm_6)\n",
    "\n",
    "#Block 2 with min size : 9 ------------------------------------------------------------------\n",
    "\n",
    "depthwiseconv1d_1 = DepthwiseConv1D(kernel_size=  4 ,padding='same',strides= 2)(relu_1)\n",
    "depthwiseconv1d_2 = DepthwiseConv1D(kernel_size=  8 ,padding='same',strides= 2)(relu_2)\n",
    "depthwiseconv1d_3 = DepthwiseConv1D(kernel_size= 16 ,padding='same',strides= 2)(relu_3)\n",
    "depthwiseconv1d_4 = DepthwiseConv1D(kernel_size= 32 ,padding='same',strides= 2)(relu_4)\n",
    "depthwiseconv1d_5 = DepthwiseConv1D(kernel_size= 64 ,padding='same',strides= 2)(relu_5)\n",
    "depthwiseconv1d_6 = DepthwiseConv1D(kernel_size=128 ,padding='same',strides= 2)(relu_6)\n",
    "\n",
    "batch_norm_1 = BatchNormalization()(depthwiseconv1d_1)\n",
    "batch_norm_2 = BatchNormalization()(depthwiseconv1d_2)\n",
    "batch_norm_3 = BatchNormalization()(depthwiseconv1d_3)\n",
    "batch_norm_4 = BatchNormalization()(depthwiseconv1d_4)\n",
    "batch_norm_5 = BatchNormalization()(depthwiseconv1d_5)\n",
    "batch_norm_6 = BatchNormalization()(depthwiseconv1d_6)\n",
    "\n",
    "relu_1 = ReLU()(batch_norm_1)\n",
    "relu_2 = ReLU()(batch_norm_2)\n",
    "relu_3 = ReLU()(batch_norm_3)\n",
    "relu_4 = ReLU()(batch_norm_4)\n",
    "relu_5 = ReLU()(batch_norm_5)\n",
    "relu_6 = ReLU()(batch_norm_6)\n",
    "\n",
    "conv1d_1 = Conv1D(filters=256,kernel_size=  4 ,padding='same')(relu_1)\n",
    "conv1d_2 = Conv1D(filters=256,kernel_size=  8 ,padding='same')(relu_2)\n",
    "conv1d_3 = Conv1D(filters=256,kernel_size= 16 ,padding='same')(relu_3)\n",
    "conv1d_4 = Conv1D(filters=256,kernel_size= 32 ,padding='same')(relu_4)\n",
    "conv1d_5 = Conv1D(filters=256,kernel_size= 64 ,padding='same')(relu_5)\n",
    "conv1d_6 = Conv1D(filters=256,kernel_size=128 ,padding='same')(relu_6)\n",
    "\n",
    "batch_norm_1 = BatchNormalization()(conv1d_1)\n",
    "batch_norm_2 = BatchNormalization()(conv1d_2)\n",
    "batch_norm_3 = BatchNormalization()(conv1d_3)\n",
    "batch_norm_4 = BatchNormalization()(conv1d_4)\n",
    "batch_norm_5 = BatchNormalization()(conv1d_5)\n",
    "batch_norm_6 = BatchNormalization()(conv1d_6)\n",
    "\n",
    "relu_1 = ReLU()(batch_norm_1)\n",
    "relu_2 = ReLU()(batch_norm_2)\n",
    "relu_3 = ReLU()(batch_norm_3)\n",
    "relu_4 = ReLU()(batch_norm_4)\n",
    "relu_5 = ReLU()(batch_norm_5)\n",
    "relu_6 = ReLU()(batch_norm_6)\n",
    "\n",
    "\n",
    "relu_1,relu_2,relu_3,relu_4,relu_5,relu_6 = two_stride_conv_block(relu_1,relu_2,relu_3,relu_4,relu_5,relu_6,filters=512)\n",
    "\n",
    "relu_1.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b0900fbe6dcf68ba8657d6a73781eea6c8e04d861aa42c88ba789e96c4944de"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tensor': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
